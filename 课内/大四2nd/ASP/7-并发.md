# Content

第7讲讨论了并发性。它讲述了多核系统如何推动越来越多的并发编程，以及使用线程、锁和共享变异状态的常用并发代码方法的热度，是有问题的。它介绍了基于事务的模型和消息传递模型，作为可能的替代方案，这可能会使未来的并发编程更加简单。

* [Content](#content)
* [1多核意义：Implications of Multicore](#1多核意义implications-of-multicore)
* [内存模型&多核系统：Memory Models and Multicore system](#内存模型多核系统memory-models-and-multicore-system)
* [Java内存模型：Memory Models](#java内存模型memory-models)
* [其他内存模型：Other Memory Models](#其他内存模型other-memory-models)
* [并发，线程，锁：Concurrency, Threads, and locks](#并发线程锁concurrency-threads-and-locks)
* [基于锁并发局限：Limitations of Lock-based Concurrency](#基于锁并发局限limitations-of-lock-based-concurrency)
* [难以编写基于锁的代码-代码不能组合：Composition of Lock-based Code](#难以编写基于锁的代码-代码不能组合composition-of-lock-based-code)
* [其他并发模型：Alternative Concurrency Models](#其他并发模型alternative-concurrency-models)
* [================](#)
* [2事务管理并发：](#2事务管理并发)
* [事务：Transactions for managing concurrency](#事务transactions-for-managing-concurrency)
* [编程模型：Programming Model](#编程模型programming-model)
* [事务编程模型限制：Consequences](#事务编程模型限制consequences)
* [IO控制：controlling I/O](#io控制controlling-io)
* [控制副作用代码：Controlling Side Effects](#控制副作用代码controlling-side-effects)
* [Monadic STM Implementation](#monadic-stm-implementation)
* [整合Haskell:Integration into Haskell](#整合haskellintegration-into-haskell)
* [整合其他语言：Integration into Other Languages](#整合其他语言integration-into-other-languages)
* [Reading](#reading)
* [================](#-1)
* [3消息传递系统：Message Passing Systems](#3消息传递系统message-passing-systems)
* [消息传递系统-定义：Message Passing Systems](#消息传递系统-定义message-passing-systems)
* [消息处理：Message Handling](#消息处理message-handling)
* [消息传递类型：Types of Message Passing](#消息传递类型types-of-message-passing)
* [消息传递类型-交互模型：Interaction Models](#消息传递类型-交互模型interaction-models)
* [消息传递类型-通信类型：Typed Communication](#消息传递类型-通信类型typed-communication)
* [消息传递类型-Naming](#消息传递类型-naming)
* [消息传递-现有实现：Implementation](#消息传递-现有实现implementation)
* [Scala+Akka例子](#scalaakka例子)
* [Rust例子](#rust例子)
* [权衡：Trade-offs](#权衡trade-offs)
* [================](#-2)
* [4竞赛条件：Race Conditions](#4竞赛条件race-conditions)
* [竞赛条件定义](#竞赛条件定义)
* [消息竞赛：Message Races](#消息竞赛message-races)
* [数据竞赛：data races](#数据竞赛data-races)
* [避免数据竞赛-不可变数据：Avoiding Data Races-Immutable Data](#避免数据竞赛-不可变数据avoiding-data-races-immutable-data)
* [避免数据竞赛-所有权转移：Avoiding Data Races-Ownership Transfer](#避免数据竞赛-所有权转移avoiding-data-races-ownership-transfer)
* [消息传递效率：Aside- Efficiency of Message Passing](#消息传递效率aside--efficiency-of-message-passing)
* [Summary](#summary)
* [================](#-3)

# 1多核意义：Implications of Multicore

讲座的第一部分谈到了多核系统对编程的影响。它概述了现代编程语言需要有一个定义明确的内存模型，并概述了Java所采用的内存模型。它谈到了线程和由锁保护的共享可变状态的常见并发模型，并讨论了这种模型的局限性和内在问题。并开始介绍其他的并发模型，这些模型将构成本讲座后面部分的讨论基础。

# 内存模型&多核系统：Memory Models and Multicore system

![](/static/2022-05-07-00-43-03.png)

- 硬件趋势：具有非统一内存访问的多核•	Hardware trends: multicore with non-uniform memory access
  - 【**计算系统正越来越多地提供多核支持。现在已经很难买到单处理器系统了，有四个或八个内核的系统已经成为主流。而拥有多达 64 个处理器内核的系统，甚至更多，也是现成的。这样做的明显后果是，并行计算现在已经成为常态。不过，也许不太明显的是，分布式内存现在也很普遍。每个处理器核心都有自己的私有缓存，不与其他核心共享。因此，每个处理器对内存都有自己独特的看法。而且，所有的处理器核心并不总是能够平等地访问内存** computing systems are increasingly providing multicore support. It’s now difficult to buy uniprocessor systems, and systems with four or eight cores are now mainstream. And systems with up to 64 processor cores, and perhaps more, are readily available. The obvious consequence of this is that parallel computation is now the norm. Perhaps less obvious, though, is that distributed memory is now also commonplace. Each processor core has its own private cache, that is not shared with other cores. And as a result, each processor has its own distinct view of memory. And memory is not always equally accessible to all the processor cores.】
    - 越来越多的核心，为了性能•	Increasing numbers of cores, for performance
    - 缓存一致性越来越昂贵 → 核心通过消息传递进行通信，内存是远程的•	Cache coherency increasingly expensive → cores communicate by message passing, memory is remote
- 【**幻灯片右上方的图显示了一个八核系统，每个核都有自己的一级缓存，但成对的核共享二级缓存。而内存通过一个共享的内存控制器集线器连接到所有的内核** The figure at the top right of the slide shows an eight core system where each core has its own level 1 cache, but pairs of cores share a level 2 cache. And where memory is connected to all of the cores via a shared memory controller hub.】
- 【**相比之下，右下角的图显示了一个系统，在这个系统中，核心不共享高速缓存，而内存被物理地连接到某些处理器上。在这种情况下，处理器内核可以直接访问附属于其所属处理器的内存，但不能直接访问其他内存。这些处理器通过硬件消息传递层进行通信，如果它们需要访问远程内存，要求其他处理器从其内存中读取并将结果传回给它们** The figure at the bottom right, in contrast, shows a system where the cores don’t share cache, and where the memory is physically attached to certain processors. In this case processor cores have direct access to the memory attached to the processor of which they are a part, but can’t directly access other memory. These processors communicate via a hardware message passing layer, if they need to access remote memory, asking the other processor to read from its memory and pass the result back to them.】
- 【**现在，这些是系统构建方式的例子。还有许多其他的例子。重要的是，内存访问不再是统一的。由于缓存的存在，不同的处理器内核对内存的内容有不同的看法。而每个内核访问内存中某一特定数值的速度将取决于缓存占用率，以及该数值在内存中的物理位置。这可能会导致不同数值的内存访问延迟出现几千倍的变化。要确保所有线程、所有内核都能看到相同的内存视图，成本太高了** Now, these are examples of the way systems are built. And there are many other examples. What’s important is that memory access is no longer uniform. The different processor cores each have a different view of the contents of memory, due to caching. And the speed at which each core can access a particular value in memory will depend on cache occupancy, and on where in memory that value is physically located. And this can lead to a several-thousand times variation in memory access latency for different values. It’s prohibitively expensive to ensure that all threads, on all cores, see the same view of memory.】
- 【**相反，为了确保良好的性能，现代系统允许不同的处理器核心看到不一致的内存视图。你在读取内存时看到的东西将取决于你的程序是在哪个核心上执行的。而且，它们引入了显式同步点。显式操作在处理器之间强制同步内存视图，每个处理器提供略微不同的基元来做到这一点。为了确保程序能够在不同类型的处理器之间可移植地运行，编程语言定义了它们的内存模型。他们需要定义语言在并发内存访问方面提供哪些保证。然后，编译器可以将其转化为机器代码，使用底层硬件提供的同步原语，以确保行为的一致性** Rather, to ensure good performance, modern systems allow different processor cores to see inconsistent views of memory. What you see when you read memory will depend what core your program is executing on. And they introduce explicit synchronisation points. Explicit operations that force synchronisation of the view of memory between processors, with each processor providing slightly different primitives to do this. To ensure that programs work portably across the different types of processor, programming languages define their memory model. They need to define what guarantees the language provides around concurrent memory accesses. And the compiler can then turn this into machine code, using the synchronisation primitives provided by the underlying hardware, to ensure consistent behaviour.】
  - 一个核的写操作何时对其他核可见？•	When do writes made by one core become visible to other cores?
    - 该语言的内存模型是什么？•	What is the memory model for the language?
    - 如果所有内核上的所有线程都有完全相同的内存视图，那就太昂贵了（"顺序一致性"）。•	Prohibitively expensive for all threads on all cores to have the exact same view of memory (“sequential consistency”)
    - 为了提高性能，允许各核对内存的看法不一致，但在同步点除外；引入具有明确语义的同步原语•	For performance, allow cores inconsistent views of memory, except at synchronisation points; introduce synchronisation primitives with well-defined semantics
    - 不同处理器的硬件保证不同•	Hardware guarantees vary between processors
    - 只要语言有明确的内存模型，语言运行时就可以隐藏差异•	Differences hidden by language runtime, provided language has a clear memory model

# Java内存模型：Memory Models

- 【**第一个定义明确内存模型的主流语言是Java。Java虚拟机保证对一个对象中的特定字段所做的改变是按程序顺序出现在做出改变的线程中的。也就是说，如果一个线程把一个值写到内存中，然后再把它读回来，只要没有其他线程写到相同的位置，那么这个线程读到的值将是它写的。这也是你所期望的**the first mainstream language to define an explicit memory model was Java. The Java virtual machine guarantees that changes made to a particular field in an object appear in program order to the thread that made the change. That is, if a single thread writes a value to memory, and then later reads it back, and provided no other threads wrote to the same location, then the value the thread reads will be that which it wrote. And this is what you’d expect.】
  - Java有一个正式定义的内存模型•	Java has a formally defined memory model
  - 在一个线程中，对一个字段的改变是按程序顺序看到的•	Changes to a field are seen in program order within a thread
- 一个线程对一个字段所做的改变对其他线程来说是可见的，如下所示。•	Changes to a field made by one thread are visible to other threads as follows: 【**然而，如果多个线程对一个字段进行读写，那么Java只能保证在某些情况下，一个线程所做的改变对其他线程是可见的** However, if multiple threads read and write to a single field, then Java only guarantees that changes made by one thread become visible to other threads in certain cases.】
  - 【**例如，如果一个线程改变了一个被标记为易失性的字段，那么这个改变是原子进行的，并立即对其他线程可见。但是，如果一个线程改变了一个没有标记为易失性的字段，那么这个改变何时对其他线程可见，取决于持有什么锁，以及线程何时被创建和销毁。有三种不同的情况** If a thread changes a field that’s marked as volatile, for example, then that change is made atomically, and immediately becomes visible to other threads. But, if a thread changes a field that’s not marked as volatile, then when that changes becomes visible to other threads depends on what locks were held, and when the threads were created and destroyed. There are three different cases.】
    - 如果一个易失性字段被改变，该改变是以原子方式完成的，并立即对其他线程可见。•	If a volatile field is changed, that change is done atomically and immediately becomes visible to other threads
  - 【**首先，如果一个线程在持有锁的同时更改了非易失性字段的值，然后释放该锁，然后某个其他线程获取该锁，则保证获取该锁的线程可以看到写入的值。其次，如果创建了一个新线程，它会看到系统的状态，就好像它刚刚获得了一个刚刚被创建线程释放的锁** Firstly, if a thread changes the value of a non-volatile field, while holding a lock, then releases that lock, and then some other thread acquires the lock, then the thread that acquires the lock is guaranteed to see the written value. Secondly, if a new thread is created, it sees the state of the system as if it had just acquired a lock that had just been released by the creating thread.】
    - 如果一个非易失性字段在持有锁的情况下被改变，然后该锁被写线程释放并被读线程获得，那么该改变对读线程是可见的。•	If a non-volatile field is changed while holding a lock, and that lock is then released by the writing thread and acquired by the reading thread, then the change becomes visible to the reading thread
    - 如果一个新的线程被创建，它就会看到系统的状态，就好像它刚刚获得了一个刚刚被创建线程释放的锁。•	If a new thread is created, it sees the state of the system as if it had just acquired a lock that had just been released by the creating thread
  - 【**第三，如果一个线程终止了，那么它所做的改变对其他线程是可见的。然而，在这三种情况之外，没有任何保证。如果两个线程同时访问一个变量而没有适当的锁，那么一个线程所做的改变可能会对另一个线程可见。也可能不可见。这取决于硬件，也取决于线程调度的具体细节，而且对程序员来说是无法预测的** And, thirdly, if a thread terminates, then the changes it made become visible to other threads. Outside of these three cases however, there are no guarantees. If two threads concurrently access a variable without proper locking, then the changes made by one thread might be visible to the other. Or they might not. It depends on hardware, and on the exact details of the thread scheduling, and it isn’t predictable to the programmer.】
    - 如果一个线程终止了，它所做的改变对其他线程是可见的•	If a thread terminates, changes it made become visible to other threads
  - 【**唯一的其他保证是，对32位字段的访问，如整数和浮点值，是原子性的。系统永远不会观察到对一个int或float的半完成的写入，即使它是错误的同步。但是这个保证对于64位的字段，比如long或double值并不成立，如果系统没有正确地锁定，就会观察到损坏的和写了一半的值。这种内存模型允许硬件的灵活性。它允许每个处理器核心可以看到不同的内存视图，而且不同线程之间的内存视图可以发生分歧。而且，只有明确使用锁的时候才需要在内核之间进行同步。如果我们注意锁定并发访问，这可以让我们写出可移植的代码，同时允许良好的性能** The only other guarantee made is that accesses to 32-bit fields, such as integer and floating point values, is atomic. The system will never observe a half-completed write to an int or a float, even if it’s incorrectly synchronised. But this guarantee doesn’t hold for 64-bit fields, such as long or double values, where corrupted and half-written, values can be observed if the system isn’t correctly locked. This memory model allows flexibility for the hardware. It allows that each processor core can see a different view of the memory, and that the views of the memory can diverge between different threads. And only the explicit use of locks requires synchronisation between cores. This lets us write portable code, if we pay attention to locking concurrent accesses, whilst allowing good performance.】
    - 对所有32位字段的访问是原子性的•	Access to all 32-bit fields is atomic
      - 也就是说，你永远无法观察到一个半途而废的写入，即使是不正确的同步。•	i.e., you can never observe a half-way completed write, even if incorrectly synchronised
      - 但对于64位的长字段和双字段来说就不是这样了，只有在字段是易失性的或持有锁的情况下，写入才是原子性的。•	This is not true for for long and double fields, which are 64-bits in size, where writes are only atomic if field is volatile or if a lock is held

# 其他内存模型：Other Memory Models

> 越来越清楚的是，所有语言都需要定义它们的内存模型。如果语言的定义没有明确说明什么时候并发访问是可见的，那么就有可能出现不同的处理器会有不同的行为，而这些差异对程序员来说是可见的。因此，要想获得正确性的希望，语言必须明确程序员可以依赖什么行为 It’s increasingly clear that all languages need to define their memory model. If the language definition isn’t explicit about when concurrent accesses become visible, it runs the risk that different processors will behave differently, and these differences will be visible to the programmer. So, to have any hope of correctness, the language has to be clear what behaviour the programmer can rely on. 

不幸的是, Java在拥有这样一个明确规定的内存模型方面是不寻常的。•	Java is unusual in having such a clearly-specified memory model

- 其他语言的规范性较差，存在新的处理器设计可能会巧妙地破坏以前的工作程序的风险•	Other languages are less well specified, running the risk that new processor designs can subtly break previously working programs
- 【**C和C++在历史上有非常糟糕的内存模型规定。这两个标准的最新版本现在已经解决了这个问题，这在很大程度上依赖于为Java所做的工作，但编译器需要很长的时间来实现这些标准，并且可以使用** C and C++ have historically had very poorly specified memory models. The recent versions of both standards have now fixed this, leaning very heavily on the work done for Java, but it’s taking a long time for compilers to implement those standards, and to become available.】
  - C和C++在历史上的内存模型规定得非常差。•	C and C++ have historically had very poorly specified memory models
    - 最新版本的标准解决了这个问题，内存模型受到了Java内存模型的很大影响。•	Latest versions of standards address this, with memory models heavily influenced by the Java memory model
    - 尚未广泛实施•	Not yet widely implemented
- 【**而Rust也还没有一个完全指定的内存模型，尽管它正在开发中。与C或C++或Java相比，为Rust指定内存模型是很复杂的，因为Rust有几种不同的引用类型和所有权规则，而且有安全和不安全代码的区别。这也是Rust目前的局限性之一** And Rust also does not yet have a fully specified memory model, although one is under development. Specifying a memory model for Rust is complicated compared to C or C++ or Java, because Rust has several different reference types and ownership rules, and because of the distinction between safe and unsafe code. This is one of the current limitations of Rust.】
  - Rust（目前）还没有一个完全指定的内存模型•	Rust does not (yet) have a fully specified memory model
    - 被认为是一个局限性--正在进行研究以解决这个问题•	Recognised as a limitation – research efforts underway to fix this
    - 多重引用类型和`unsafe`代码使其复杂化•	Complicated by multiplicity of reference types and unsafe code

# 并发，线程，锁：Concurrency, Threads, and locks

![](/static/2022-05-07-01-05-11.png)

- 【**正如我们所看到的，一种语言的内存模型明确地与它管理线程间锁定和通信的方式联系在一起。大多数操作系统以多个进程的形式向应用程序提供并发性，每个进程可能包含多个执行线程。而进程之间是相互隔离的，不共享内存。不过，一个进程中的线程会共享对公共内存池的访问，并利用同步来管理对该共享内存的访问。它们需要对访问共享资源的关键部分进行显式锁定** As we’ve seen, the memory model of a language is explicitly tied into the way it manages locking and communication between threads. Most operating systems expose concurrency to applications in the form of multiple processes, each potentially containing multiple threads of execution. And processes are isolated from each other, and don’t share memory. Threads within a process, though, share access to a common pool of memory, and make use of synchronisation to manage access to that shared memory. They require explicit locks around critical sections where shared resources are accessed.】
  - 操作系统将并发性暴露为进程 和线程•	Operating system exposes concurrency as processes and threads
    - 进程通过独立的内存区域进行隔离•	Processes are isolated with separate memory areas
    - 线程共享访问一个共同的内存池•	Threads share access to a common pool of memory
      - 大多数操作系统从进程和消息传递开始，后来由于程序员的需求而增加了线程。•	Most operating systems started with processes and message passing, and added threads later due to programmer demand
- 【**如何做到这一点取决于语言的不同。例如，在Java中，锁是由同步方法和同步块的实现提供的。在C语言中，它们由pthreads库以pthread_mutex_lock()和pthread_mutex_unlock()的形式提供，在C++中由std::线程类提供。这些提供了同步化的基元，并确保对共享数据的访问遵循语言的内存模型。而且，在这种受保护的、锁定的区域之外，对共享内存的并发访问几乎没有保证**  How this is done depends on the language. In Java, for example, the locks are provided by the implementation of synchronised methods and synchronised blocks. In C, they’re provided by the pthreads library, in the form of pthread_mutex_lock() and pthread_mutex_unlock(), in C++ by the std::thread class. And these provide the synchronisation primitives, and ensure access to shared data follows the memory model of the language. And, outside of such protected, such locked, regions, there are very few guarantees about concurrent accesses to shared memory.】
- 内存模型规定了对共享内存的并发访问是如何进行的•	The memory model specifies how concurrent access to shared memory works
  - 通过关键部分的显式锁来实现同步•	Synchronisation by explicit locks around critical sections
    - Java中的同步方法和语句•	synchronized methods and statements in Java
    - C语言中的pthread_mutex_lock()/pthread_mutex_unlock() •	pthread_mutex_lock()/pthread_mutex_unlock() in C
  - 通过易失性字段进行同步•	Synchronisation by volatile fields
  - 对共享内存的无锁并发访问的有限保证•	Limited guarantees about unlocked concurrent access to shared memory

# 基于锁并发局限：Limitations of Lock-based Concurrency

基于锁的并发性的主要问题。•	Major problems with lock-based concurrency:【**提供多个线程，并使用锁来保护对共享内存的访问，这种方法是非常普遍的。但它也确实存在问题** The approach of providing multiple threads, and using locks to protect access to shared memory, is extremely common. But it’s also really problematic.】

- 【**事实证明，很难为语言定义一个内存模型，以提供良好的性能，同时也允许程序员对代码进行推理。我们很难知道什么时候锁是正确的。失败是无声的。锁定不正确的代码往往编译得很好，但错误往往会在重负荷下表现出来。这使得这种代码难以编写，也难以调试。平衡性能和正确性是困难的。过度或不足的锁定程序是很容易的。增加太多或者太少的锁。如果你锁的太多，或者锁的时间太长，那么性能就会变差。但如果锁得太少，代码就会偶尔出现不可预知的故障。很难强制执行正确的锁，也很难保证免于死锁** It’s proven difficult to define a memory model for a languages that provides good performance, whilst also allowing programmers to reason about the code. It’s difficult to know when the locking is done correctly. Failures are silent. Incorrectly locked code tends to compile just fine, but errors tend to manifest themselves under heavy load. This make such code hard to write, and hard to debug. Balancing performance and correctness is difficult. It’s easy to over- or under-lock programs. To add too many, or too few locks. And if you lock too much, or for too long, then the performance is bad. But lock too little, and the code occasionally and unpredictably fails. It’s difficult to enforce correct locking, and difficult to guarantee freedom from deadlocks.】
  - 难以定义一个能够实现良好性能的内存模型，同时允许程序员对代码进行推理•	Difficult to define a memory model that enables good performance, while allowing programmers to reason about the code
  - 在编写代码时很难保证正确性•	Difficult to ensure correctness when composing code
  - 难以强制执行正确的锁定•	Difficult to enforce correct locking
  - 难以保证不出现死锁•	Difficult to guarantee freedom from deadlocks
  - 失败是无声的--错误往往只在重载下才会显现出来•	Failures are silent – errors tend to manifest only under heavy load
  - 难以平衡性能和正确性--容易造成系统过锁或欠锁•	Balancing performance and correctness difficult – easy to over- or under-lock systems

# 难以编写基于锁的代码-代码不能组合：Composition of Lock-based Code

![](/static/2022-05-07-01-13-59.png)

> 而且，要**编写使用锁的代码也很困难**。我认为，**这才是反对将锁作为同步机制的真正理由**。至少在原则上，使用锁来控制对共享数据的访问，是可以正确编写小规模代码的。这并不容易，而且大多数人都做错了，但原则上是可以做到的 And it’s difficult to compose code that uses locks. And this, I think, is the real argument against locks as synchronisation mechanism. In principle, at least, it’s possible to write small-scale code correctly using locks to control access to shared data. It’s not easy, and most people get it wrong, but in principle it’s possible.
>  **但问题是，基于锁的代码并不能组合。如果你有两个分别正确使用锁的函数，那么将它们组合起来的结果可能是不正确的** The problem is, though, is that lock-based code doesn’t compose. If you have two functions that each use locking correctly, then the result of combining them may not be correct.
>  大家用来说明这个问题的例子是一个银行系统。假设你有一个银行账户类，它正确地使用锁来保护对账户的访问。你想写一个程序，在两个账户之间转钱。而这个程序不应该暴露中间状态。也就是说，钱要么在A账户中，要么在B账户中，但不应该出现钱同时在两个账户中，或者两个账户都不在的情况 The example everyone uses to illustrate this is a banking system. Assume you have a bank account class, that correctly uses locks to protect access to the account. You want to write a program to transfer money between two accounts. And that program shouldn’t expose the intermediate state. That is, the money should either be in account A, or it should be in account B, but it shouldn’t be possible to see a situation where the money is in both accounts, or in neither account. 
> 不幸的是，对各个账户的锁定并不能保护这一点。即使账户被正确锁定，另一个线程仍有可能观察到中间状态，即钱从一个账户中消失，但没有到达另一个账户。单独的操作是正确的，但综合的操作是不正确的。**我们需要添加额外的锁来使组合正确。而这是锁工作方式的根本。它不能通过仔细的编码来解决。这是锁的抽象本身的一个限制**。Unfortunately, the locking on the individual accounts doesn’t protect this. Even if the accounts are correctly locked, it’s still possible for another thread to observe the intermediate state where, the money is gone from one account but not arrived in the other. The individual operations are correct, but the combined operation is not. We need to add extra locks to make the combination correct. And this is fundamental to the way locks work. It cannot be fixed by careful coding. It’s a limit of the locking abstraction itself.

- 从理论上讲，使用锁的小规模代码的正确性可以通过仔细的编码来保证•	Correctness of small-scale code using locks can, in theory, be ensured by careful coding
- 一个更基本的问题：基于锁的代码不能组合更大的规模•	A more fundamental issue: lock-based code does not compose to larger scale
- 假设一个正确锁定的银行账户类，有 方法从账户中贷出和借出资金•	Assume a correctly locked bank account class, with methods to credit and debit money from an account
- 想从a中取钱并将其转移到b中，而不暴露出钱在两个账户中的中间状态•	Want to take money from a and move it to b, without exposing an intermediate state where the money is in neither account
- 在转移过程中，如果不锁定对a和b的所有其他访问，就无法做到。•	Can’t be done without locking all other access to a and b while the transfer is in progress
- 单独的操作是正确的，但综合的操作是不正确的 •	The individual operations are correct, but the combined operation is not
- 这是缺乏抽象性，是基于锁的并发模型的限制，不能通过仔细的编码来解决。•	This is lack of abstraction a limitation of the lock-based concurrency model, and cannot be fixed by careful coding
- 锁定要求构成了一个对象的API的一部分•	Locking requirements form part of the API of an object

# 其他并发模型：Alternative Concurrency Models

> 由于这些原因，现在是我们再次思考替代性并发模型的时候了。多核系统现在已经无处不在了。并发性无处不在。**但是，由锁保护的共享访问的多线程代码是非常难以正确编写的。即使写对了，在组合成完整的系统时，也很容易出现故障。在下面的部分中，将谈论基于锁的并发的两个替代方案：事务和消息传递**。And for these reasons, it’s time we thought again about alternative concurrency models. Multicore systems are now ubiquitous. Concurrency is everywhere. But multithreaded code with shared access protected by locking is incredibly hard to write correctly. And even when written correctly, is prone to failures when combined into complete systems. In the following parts, I’ll talk about two alternatives to lock-based concurrency: transactions and message passing.

- 并发性越来越重要•	Concurrency increasingly important
- 多核系统现在无处不在•	Multicore systems now ubiquitous
- 软件和硬件设备之间的异步互动•	Asynchronous interactions between software and hardware devices
- 线程和同步基元有问题•	Threads and synchronisation primitives problematic

- 是否有替代方案可以避免这些问题？•	Are there alternatives that avoid these issues?
  - 事务•	Transactions
  - 消息传递•	Message passing

# ================

# 2事务管理并发：

本讲座的第二部分讨论了原子事务作为一种替代的并发编程模型。它回顾了事务的ACID属性，并介绍了事务编程模型及其后果和好处。它讨论了这种编程风格如何适合Haskell，以及Monad编程风格，任何为什么它不适合更多主流编程语言。The second part of this lecture discusses the atomic transactions as an alternative concurrent programming model. It reviews the ACID properties of transactions, and introduces the transactions programming model and its consequences and benefits. It discusses how this style of programming is a good fit for Haskell, and the monadic programming style, any why it's not a good fit for more mainstream programming languages.

# 事务：Transactions for managing concurrency

- 锁的替代方案：使用原子事务来管理并发性•	An alternative to locking: use atomic transactions to manage concurrency
  - 【**原子事务的目标是提供一种管理并发性的替代方法，避免使用多线程和由锁管理的共享可变状态所固有的问题。其基本思想是将一个程序构造成一个原子事务的序列，不同线程的事务可以并发进行。每个事务都包裹着一些计算，这样它要么成功，要么完全失败，因此中间状态对其他线程是不可见的** The goal of atomic transactions is to provide an alternative way of managing concurrency, that avoids the problems inherent in the use of multithreading with shared mutable state managed by locks. The fundamental idea is to structure a program as a sequence of atomic transactions, where transactions in different threads can proceed concurrently. Each transaction wraps some computation, such that it either succeeds or it fails in its entirety, and so that intermediate states are not visible to other threads The execution of the transactions is managed by a runtime, and the runtime ensures that the transactions obey the usual four ACID properties】
  - 一个程序是一连串并发的原子行动•	A program is a sequence of concurrent atomic actions
  - 原子动作的成功或失败都是完整的，中间状态对其他线程是不可见的。•	Atomic actions succeed or fail in their entirety, and intermediate states are not visible to other threads
- 运行时必须确保行动具有通常的ACID属性。•	The runtime must ensure actions have the usual ACID properties:
  - 原子性--对数据的所有改变都被执行，或者不被执行•	Atomicity – all changes to the data are performed, or none are 【**首先，每个事务都是原子性的。也就是说，它完全成功或失败，任何中间状态对其他线程都不可见。一个事务中的所有动作都会被执行，或者都不会被执行** Firstly, that each transaction is atomic. That is, it succeeds or fails in its entirety, and any intermediate states are not visible to other threads. All of the actions in a transaction are performed, or none of them are. 】
  - 一致性--当一个事务开始和结束时，数据处于一致的状态•	Consistency – data is in a consistent state when a transaction starts, and when it ends 【**其次，事务是一致的。运行时确保系统中的数据在事务开始时处于一致的状态，在事务结束时处于一致的状态，并且在任何时候，不一致的值都对系统的其他部分可见。如果事务成功，该一致状态反映了已完成的行动。如果它失败了，其影响会被干净地回滚，状态就像事务从未被尝试过一样** Secondly, that transactions are consistent. The runtime ensures that the data in the system is in a consistent state when the transaction starts, is left in a consistent state when it ends, and at no point are inconsistent values visible to the rest of the system. If the transaction succeeds, that consistent state reflects the completed action. If it fails, the effects are cleanly rolled back, and the state is as-if the transaction was never attempted.】
  - 隔离性--一个事务的中间状态对其他事务是不可见的•	Isolation – intermediate states of a transaction are invisible to other transactions 【**第三，事务是隔离的。当然，一个事务的执行将包括一些步骤，一些中间状态。运行时确保这些中间状态在事务之外是不可见的。对于程序的其他部分来说，事务的进行是不可分割的、完全的，或者根本就不是** Third, transactions are isolated. The execution of a transaction will, of course, comprise a number of steps, a number of intermediate states. The runtime ensures that none of those intermediate states are visible outside of the transaction. To the rest of the program, the transaction proceeds indivisibly and completely, or not at all.】
  - 持久性--一旦提交，事务的结果就会持续存在。•	Durability – once committed, results of a transaction persist 【**而且，最后，事务是持久的。一个事务可能成功，也可能失败并被回滚。但是，如果它成功了并提交了结果，那么这个结果将持续存在。一个成功的事务将永远不会被回滚** And, finally, transactions are durable. A transaction may succeed, or it may fail and be rolled back. But, if it succeeds and commits its result, then that result will persist. A successful transaction will never be rolled back.】
- 优点。
  - 【**这些属性被称为ACID属性，你可能很熟悉，因为它们经常适用于数据库系统。为什么以这种方式构建一个程序是有意义的呢？因为以这种方式结构的事务可以任意组成，而不影响正确性。正如我们在上一部分看到的，以银行账户类为例，两个正确锁定的银行账户对象，在组合时，可以产生一个暴露内部状态的系统。而这个问题并不发生在事务上。无论它们是如何组成的，都不会影响代码的正确性。而且，事务也避免了由于以错误的顺序获取锁而可能发生的死锁，因为没有锁。而且它们还避免了竞赛条件** These, properties, known as the ACID properties, are probably familiar to you, since they frequently apply to database systems. Why might it make sense to structure a program in this way? Because transactions structured in this way can be composed arbitrarily, without affecting correctness. As we saw in the previous part, with the example of the bank account class, how two correctly locked bank account objects, when combined, could produce a system that exposed the internal state. And this problem doesn’t occur with transactions. No matter how they are composed, it doesn’t affect correctness of the code. And transactions also avoid deadlocks that can occur due to acquiring locks in the wrong order, since there are no locks. And they avoid race conditions.】
  - 事务可以任意组成，而不影响正确性•	Transactions can be composed arbitrarily, without affecting correctness
  - 由于没有锁，所以避免了由于不正确的锁造成的死锁。•	Avoid deadlock due to incorrect locking, since there are no locks

# 编程模型：Programming Model

简单的编程模型。•	Simple programming model:

- 【**使用事务的系统的编程模型是直接的。代码块被标记为原子性的。运行时执行这些代码块，确保执行尊重ACID属性，并允许原子块相对于其他原子块并发运行** The programming model for systems using transactions is straight forward. Blocks of code are labelled as atomic. And the runtime executes those code blocks, ensuring that execution respects the ACID properties, and allows atomic blocks to run concurrently with respect to other atomic blocks】
  - 代码块可以被标记为 atomic{...}。•	Blocks of code can be labelled atomic {…}
  - 相对于每一个其他的 atomic{...}块，并发和原子地运行--控制并发并确保数据结构一致•	Run concurrently and atomically with respect to every other atomic {…} blocks – controls concurrency and ensures consistent data structures
- 通过乐观的事务来实现•	Implemented via optimistic transactions 【**而程序员不必担心锁定或同步的问题。运行时负责处理所有这些。这是用乐观的事务实现的** And the programmer doesn’t have to worry about locking or synchronisation. The runtime takes care of all that. This is implemented using optimistic transactions.】
  - 维护线程本地事务日志，记录原子块的每一次内存读写。•	A thread-local transaction log is maintained, records every memory read and write made by the atomic block 【**当一个原子块进入时，运行时开始维护一个线程本地事务日志。这个事务日志维护着原子块的每一次内存读写和每一次潜在的I/O操作的记录** When an atomic block is entered, the runtime starts to maintain a thread local transaction log. This transaction log maintains a record of every memory read or write, and every potential I/O operation, made by the atomic block.】
  - 当一个原子块完成后，日志被验证，以检查它是否看到了一致的内存视图•	When an atomic block completes, the log is validated to check that it has seen a consistent view of memory 【**当块完成后，事务日志被验证，以检查它是否看到了一个一致的内存视图** When the block completes, the transaction log is validation, to check that it saw a consistent view of memory.】
  - 【**如果验证成功，那么这个原子块，也就是事务，就会把它的变化提交给内存。如果不成功，如果这个事务与另一个事务竞争而输掉了，那么这个原子块，也就是这个事务，就会被滚动到开头，撤销任何变化，并从头开始重试** If the validation succeeds, then the atomic block, the transaction, commits its changes to memory. If not, if this transaction was competing with another transaction and lost out, then the atomic block, the transaction, is rolled block to the beginning, undoing any changes, and retried from scratch.】
    - 如果验证成功，事务就会将其变化提交给内存；如果不成功，事务就会回滚，并从头开始重试。•	If validation succeeds, the transaction commits its changes to memory; if not, the transaction is rolled-back and retried from scratch
  - 【**当然，我们的假设是，事务之间的冲突很少，而且大多数原子块在第一次就完成并提交了结果。如果情况不是这样，如果有很多冲突的事务，那么由于反复回滚，进度会很慢，但事务最终会取得进展** The assumption, of course, is that conflicts between transaction are rare, and that most atomic blocks complete and commit their results the first time. And if that’s not the case, if there are many conflicting transactions, then progress will be slow, due to repeated rollbacks, but the transactions will eventually make progress.】
    - 如果冲突的事务导致重复的验证失败，进展可能会很慢，但最终会发生。•	Progress may be slow if conflicting transactions cause repeated validation failures, but will eventually occur

# 事务编程模型限制：Consequences

![](/static/2022-05-07-03-01-23.png)

- 如果事务日志无法验证，事务可以自动重新运行。•	Transactions may be re-run automatically, if their transaction log fails to validate
  - 【**现在，正如我们所看到的，如果事务日志无法验证，运行时将回滚并重试事务，因为它们在竞争中输给了同时进行的其他事务之一。这样做的一个结果是，需要有可能回滚和重试事务。为了使之成为可能，运行时必须对事务行为进行一些限制** Now, as we’ve seen, the runtime will roll-back and retry transactions, if their transaction log fails to validate because they lose out in competition to one of the other transactions proceeding concurrently. A consequence of this, is that it needs to be possible to roll-back and retry a transaction. And to make this possible, the runtime has to place some restrictions on transaction behaviour.】
- 对事务行为进行了限制。•	Places restrictions on transaction behaviour:
  - 事务必须是参考透明的•	Transactions must be referentially transparent 【**关键的限制是，事务必须是透明的。也就是说，事务返回的结果必须只取决于它的输入，而且每次执行时必须产生相同的结果** The key restriction is that a transaction needs to be referentially transparent. That is, the result returned by a transaction must depend solely on its inputs, and it must generate the same result each time it executes.】
  - 【**而且，在事务过程中，它不能执行I/O操作。它不能做任何不可撤销的事情。例如，幻灯片上的代码样本是有问题的，因为一个并发的事务可能会修改n或k的值。现在，当事务日志被验证时，在原子块结束时，当提交或回滚事务时，这将被检测到。但这可能太晚了，无法阻止导弹的意外发射** And it must not perform I/O operations during the transaction. It must not do anything irrevocable. The code sample on the slide is problematic, for example, because a concurrent transaction might modify the values of n or k. Now, this would be detected when the transaction log is validated, at the end of the atomic block, when it’s time to commit or rollback the transaction. But that might be too late to stop the missiles being launched by accident.】
    - 事务必须不做任何不可撤销的事情。•	Transactions must do nothing irrevocable:
      - 如果由于doMoreStuff()导致的验证失败而被重新运行，可能会多次发射导弹•	Might launch the missiles multiple times, if it gets re-run due to validation failure caused by doMoreStuff()
      - 如果一个并发事务在事务运行时修改了n或k，可能会意外地发射导弹（会导致事务失败，但来不及阻止发射）。•	Might accidentally launch the missiles if a concurrent transaction modifies n or k while the transaction is running (will cause transaction failure, but too late to stop the launch)
  - 这些限制必须被强制执行，否则我们就用难以发现的锁定错误换取难以发现的事务错误•	These restrictions must be enforced, else we trade hard-to-find locking bugs for hard-to-find transaction bugs 【**所以运行时系统必须强制执行这些限制，否则我们就用难以发现的锁定错误换取难以发现的事务一致性错误** So the runtime system has to enforce these restrictions, else we’ve just traded hard to find locking bugs, for hard to find transaction consistency bugs.】

# IO控制：controlling I/O

- 【**所以，我们看到的是，不受限制的I/O打破了事务隔离。如果一个事务可以读取或写入文件，如果它可以通过网络发送或接收数据，如果它可以接受来自鼠标或键盘的输入，更新显示器，播放或录制声音，等等，那么在提交之前就可以观察到该事务的进展。这就破坏了ACID的特性。它破坏了隔离性。而且，它使事务无法回滚** So, what we see is that unrestricted I/O breaks transaction isolation. If a transaction can read or write files, if it can send or receive data over the network, if it can take input from the mouse or keyboard, update the display, play or record sound, etc., then the progress of the transaction can be observed before it commits. This breaks the ACID properties. It breaks isolation. And it makes it impossible to roll-back the transaction. 】
  - 不受限制的I/O破坏了事务隔离•	Unrestricted I/O breaks transaction isolation
    - 读取和写入文件•	Reading and writing files
    - 通过网络发送和接收数据•	Sending and receiving data over the networks
    - 接受鼠标或键盘输入；改变显示•	Taking mouse or keyboard input; changing the display
- 要求用语言控制I/O的执行时间•	Require language control of when I/O is performed 【**为了解决这个问题，语言和运行时需要控制I/O的执行时间。他们需要从标准库中移除允许不受限制的I/O的全局函数，而是用允许控制I/O发生时间的版本来取代它们** To address this, the language and runtime need to control when I/O is performed. They need to remove the global functions that allow unrestricted I/O from the standard library, instead replace them with versions that allow control over when I/O can occur.】
  - **从标准库中删除执行I/O的全局函数**•	Remove global functions to perform I/O from the standard library
  - 【**一种工作方式是，系统提供一个I/O上下文对象，作为参数传递给main()。这个对象将拥有允许读写文件、访问标准输入和标准输出的方法，等等。而诸如printf()等函数将成为I/O上下文对象的方法。如果一个函数需要执行I/O，那么它就需要通过这个I/O内容对象，这样它就可以调用适当的方法。这将允许控制哪些函数可以执行I/O。例如，如果你想阻止一个事务写入一个文件，就不要把I/O内容对象传给它，它就不能读写任何文件。现在，这不是Rust、C、Java或任何其他主流语言的I/O工作方式，尽管可以说它也许应该是。但这是I/O在Haskell中的工作方式。所描述的I/O上下文对象本质上是I/O monad，而Haskell表明这种控制I/O的方法是可行的**】 One way this could work is if the system provided an I/O context object, that was passed as a parameter to main(). This object would have methods that allow reading and writing to files, access to standard input and standard output, and so on. And functions such as printf() would become methods on the I/O context object. And if a function needs to perform I/O, then it would need to be passed this I/O content object, so it could invoke the appropriate methods. This would allow control over what functions can perform I/O. If you want to prevent a transaction from writing to a file, for example, don’t pass it the I/O context object, and it can’t read or write to any files. Now, this is not how I/O works in Rust, or in C, or in Java, or in any other mainstream languages, although arguably it maybe should be. But it is how I/O works in Haskell. The I/O context object I’m describing is essentially the I/O monad, and Haskell shows that this approach to controlling I/O can work.
    - 添加一个I/O上下文对象，在main()的本地，明确传递给需要执行I/O的函数•	Add an I/O context object, local to main(), passed explicitly to functions that need to perform I/O
      - 将以这种方式行事的套接字与通常不以这种方式行事的文件I/O进行比较。•	Compare sockets, that behave in this manner, with file I/O that typically does not
      - I/O函数（例如printf()和friends）就成为I/O上下文对象的方法。•	I/O functions (e.g., printf() and friends) then become methods on the I/O context object
      - I/O上下文不被传递给事务，所以它们不能执行I/O •	The I/O context is not passed to transactions, so they cannot perform I/O
      - 示例：Haskell中的IO monad•	Example: the IO monad in Haskell

# 控制副作用代码：Controlling Side Effects

- 必须控制有副作用的代码•	Code that has side effects must be controlled 【**除了控制I/O操作外，原子事务还需要控制副作用** In addition to controlling I/O operations, atomic transactions require control over side effects.】
  - 纯粹的和引用透明的函数可以正常执行•	Pure and referentially transparent functions can be executed normally 【**那些参考透明的函数，只依赖于它们的参数，不依赖于对共享状态和共享内存的访问，可以被正常访问。但是，如果一个函数访问了可能与其他函数共享的内存，如果它操作了可能与其他事务共享的堆上的值，那么这种访问必须被控制** Functions that are referentially transparent, that only depend on their arguments and that don’t depend on access to shared state, to shared memory, can be accessed normally. But, if a function accesses memory that might be shared with other functions, if it manipulates a value on the heap that might be shared with other transactions, then that access must be controlled】
  - 【**事务中的函数可以执行内存访问，但运行时必须跟踪这些访问。运行时必须跟踪事务中的内存读写，这样它就可以验证与其他正在进行的事务没有冲突，这样它就可以在必要时回滚任何变化，如果发生这种冲突。这可以在软件中完成，由语言运行时通过将内存访问包裹在某种智能指针对象中。这种方法被称为软件事务性内存，STM。另外，一些处理器提供硬件支持来加速这种指针跟踪**. Functions within a transaction can perform memory accesses, but the runtime must track those accesses. The runtime must track memory reads and writes during a transaction, so it can validate that there are no conflicts with other ongoing transactions, and so that it can roll-back any changes, if necessary, if such conflicts occur. And this can be done in software, by the language runtime, by wrapping memory access in some kind of smart pointer object. And this approach is known as software transactional memory, STM. Alternatively, some processors provide hardware support to accelerate such pointer tracking.】
    - 只执行内存操作的函数可以正常执行，前提是事务日志跟踪内存操作，并在事务提交前对其进行验证--并有可能将其回滚。•	Functions that only perform memory actions can be executed normally, provided transaction log tracks the memory actions and validates them before the transaction commits – and can potentially roll them back
      - 内存操作是指在堆上操作数据的操作，其他线程可以看到这些数据。•	A memory action is an operation that manipulates data on the heap, that could be seen by other threads
      - 跟踪内存操作可以通过语言运行时（STM；软件事务性内存），或者通过硬件强制事务性内存行为和回滚来完成。•	Tracking memory actions can be done by language runtime (STM; software transactional memory), or via hardware enforced transactional memory behaviour and rollback
- 与控制I/O的原理类似 •	Similar principle as controlling I/O 【**其原理与控制I/O的原理类似。不允许不受限制的堆访问，就像不允许不受限制的文件访问一样，并提供一个内存事务背景。如果原子块要访问内存，需要将这个事务上下文传递给原子块，允许它们只执行经过检查的内存访问，并在必要时提供验证和回滚内存访问的能力。再说一遍，这也许不是主流，但对于Haskell程序员来说，它是熟悉的state monad**  The principle is similar to that for controlling I/O. Disallow unrestricted heap access, in the same way unrestricted file access way disallowed, and provide a memory transaction context. And require this transaction context to be passed to atomic blocks if they are to access memory, to allow them to perform only checked memory access, and to provide the abilIty to validate and rollback memory accesses if necessary. And, again, this is not, perhaps, mainstream, but it’s familiar to Haskell programmers as the state monad.】
  - 不允许不受限制的堆访问--只看到事务上下文中的数据 •	Disallow unrestricted heap access – only see data in transaction context
  - 明确地将事务上下文传递给事务；这有执行事务性内存操作的操作，并在事务提交失败时回滚 •	Pass transaction context explicitly to transactions; this has operations to perform transactional memory operations, and rollback if the transaction fails to commit
  - 与Haskell中的state monad非常相似 •	Very similar to the state monad in Haskell

# Monadic STM Implementation

![](/static/2022-05-07-19-43-13.png)

- 【**所以，我们已经看到，Haskell限制了函数执行I/O的能力，或通过使用单子来访问内存。单子是Haskell中不太为人所知的部分之一。作为一个不是Haskell程序员的人，我对它们的看法是，Haskell定义了一组可以在特定环境下执行的动作，以及一些规则，即单子，用于在该环境下将这些动作连在一起** So, we’ve seen that Haskell limits the ability of a function to perform I/O, or access memory by using monads. Monads are one of the less well understood parts of Haskell. The way I think of them, as someone who’s not a Haskell programmer, is that Haskell defines a set of actions that can be performed in a certain context, along with some rules, a monad, for chaining together those actions in that context.】
  - 单子→功能语言中控制副作用的方法•	Monads → way to control side-effects in functional languages
  - 一个单子M a描述了一个动作（即一个函数），它产生一个类型为a的结果，可以在上下文M中执行。•	A monad M a describes an action (i.e., a function) that, produces a result of type a, that can be performed in the context M
  - 以及在该上下文中进行连锁操作的规则。•	Along with rules for chaining operations in that context
- 一个常见的用途是**控制I/O**操作。•	A common use is for controlling I/O operations:
  - 【**例如，正如我们在幻灯片上看到的，putChar函数接收一个字符，并返回一个将该字符写入I/O上下文的动作。getChar函数返回一个动作，从I/O上下文中检索一个字符。以此类推。主函数持有I/O上下文，需要读取或写入文件的函数被标记为在该上下文中操作。如果一个函数没有以这种方式被标记，它就不能读或写文件。这使我们有能力在原子事务中限制I/O**  The putChar function, for example, as we see on the slide, takes a character and returns an action that writes the character to the I/O context. The getChar function returns an action that retrieves a character from the I/O context. And so on. The main function holds the I/O context, and functions that need to read or write to files are tagged as operating in that context. And if a function is not tagged in this way, it can’t read or write to files. And this gives us the ability to restrict I/O during atomic transactions.】
    - putChar函数接收一个字符，在IO 上下文进行操作以添加该字符，并且不返回任何东西•	The putChar function takes a character, operates on the IO context to add the character, and returns nothing
    - getChar函数对IO上下文进行操作，返回一个字符。•	The getChar operates on the IO context to return a character
    - 主函数有一个IO上下文，它包裹并执行其他操作•	The main function has an IO context, that wraps and performs other actions
  - I/O单子类型的定义确保了没有被传递给IO上下文的函数不能执行I/O操作。•	The definition of the I/O monad type ensures that a function that is not passed the IO context cannot perform I/O operations
- 软件事务性内存实现的一部分：确保atomic{...}函数不允许它被传递给IO上下文，从而防止I/O. •	One part of a software transactional memory implementation: ensure type of the atomic{…} function does not allow it to be passed an IO context, hence preventing I/O 【**我们确保原子块的定义不被标记为I/O上下文的一部分。这就提供了一种防止原子事务读写文件的方法。因为Haskell的原因，它被复杂的类型理论抽象所包裹，但本质上它只是限制了对执行I/O的函数的访问** We make sure the definition of the atomic block isn’t tagged as being part of the I/O context. This gives a way of preventing atomic transactions from reading or writing files. It’s wrapped in complex type-theoretic abstractions, because Haskell, but essentially it’s just restricting access to the functions that perform I/O.】

---

![](/static/2022-05-07-21-02-16.png)
![](/static/2022-05-07-21-02-23.png)

- **如何跟踪副作用内存操作**？•	How to track side-effecting memory actions? 【**这对控制I/O是有效的，但如何控制对内存的访问呢**】
- 【**Haskell使用了一个类似的方法。状态单子被用来定义STM，软件事务性内存的上下文。函数newTVar定义了一个交易型变量，它存在于这样的上下文中。它持有一个对堆上潜在共享值的引用。readTVar和writeTVar函数返回动作，允许在STM上下文中读写该共享值，但与运行时和原子事务实现协调，以跟踪不同事务之间对该值的冲突访问。原子块的实现提供了一个STM上下文，允许在事务中使用事务性变量，但禁止在该上下文之外使用这些变量。而且，正如我们从幻灯片中看到的那样，原子块返回一个I/O上下文，实际上是将这些值读写到内存中** Haskell uses a similar approach. The state monad is used to define an STM, software transactional memory, context. The function, newTVar, defines a transactional variable, that exists within such a context. This holds a reference to a potentially shared value on the heap. And the readTVar and writeTVar functions return actions that allow reading and writing to that shared value within an STM context, but that coordinate with the runtime and atomic transaction implementation, to track conflicting access to such values between different transactions. And the implementation of an atomic block provides an STM context that allows the transactional variables to be used within a transaction, but prohibits their use outside that context. And, as we see from the slide, the atomic block returns an I/O context that actually reads and write the values to memory.】
    - 定义一个STM单子来包装事务•	Define an STM monad to wrap transactions
    - 基于状态单子；通过TVar类型管理副作用•	Based on the state monad; manages side-effects via a TVar type
    - newTVar函数接收一个类型为a的值，返回新的 持该值的TVar，用STM单子包装。•	The newTVar function takes a value of type a, returns new TVar to hold the value, wrapped in an STM monad
    - readTVar函数接收一个TVar并返回一个STM上下文；当执行时，返回该TVar的值；writeTVar函数接收一个TVar和一个值，返回一个STM上下文，可以验证事务并将值提交到TVar中。•	readTVar takes a TVar and returns an STM context; when performed this returns the value of that TVar; writeTVar function takes a TVar and a value, returns an STM context that can validate the transaction and commit the value to the TVar
  - atomic {...}函数在一个STM上下文中操作，并返回一个IO上下文，执行验证和提交事务所需的操作 •	The atomic {…} function operates in an STM context and returns an IO context that performs the operations needed to validate and commit the transaction
    - newTVar、readTVar和writeTVar函数需要一个STM动作，所以只能在提供这种动作的原子块的上下文中运行。•	The newTVar, readTVar, and writeTVar functions need an STM action, and so can only run in the context of an atomic block that provides such an action
    - 在事务中禁止I/O，因为原子{...}中的操作不能访问I/O上下文 •	I/O prohibited within transactions, since operations in atomic {…} don’t have access to I/O context

# 整合Haskell:Integration into Haskell

> 事务性内存与Haskell很适合。它之所以有效，是因为Haskell提供了必要的类型系统特性来控制I/O和控制其他副作用。纯函数的使用、懒惰评估和单体，都确保了交易语义和ACID属性得以保留。Transactional memory is a good fit with Haskell. And the reason it works is that Haskell provides the necessary type system features to control I/O and control other side effects. The use of pure functions, lazy evaluation, and monads, all ensure that the transaction semantics, the ACID properties, are preserved.
> STM上下文和事务变量的使用，约束和限制了对内存的访问，并跟踪副作用，允许冲突的事务被检测和回滚。原子块的定义，确保了事务不在IO上下文中，防止了对文件的读写，或以其他方式执行I/O。 The STM context, and the use of transactional variables, constrains and limits access to memory, and tracks side effects, allowing conflicting transactions to be detected and rolled back. And the definition of the atomic block, that ensures the transaction is not in the IO context, prevents reading or writing to files, or otherwise performing I/O.
> 其结果是干净而优雅的。这是一个很好的关于并发的抽象。它允许函数的组合，而不需要担心锁定问题。它不会出现死锁。而且，它很容易推理，很容易使用。 The result is clean and elegant. It’s a nice abstraction for concurrency. It allows composition of functions without worrying about locking. It can’t deadlock. And it’s easy to reason about, easy to use.

- 事务性内存与Haskell很适合•	Transactional memory is a good fit with Haskell
  - 纯函数和单子确保交易语义得以保留•	Pure functions and monads ensure transaction semantics are preserved
  - 副作用包含在一个原子{...}块的STM上下文中•	Side-effects are contained in STM context of an atomic {…} block
    - TVar实现负责跟踪副作用•	The TVar implementation is responsible for tracking side effects
    - 原子{...}块验证，然后提交事务（通过返回一个在IO上下文中执行的动作）。•	The atomic {…} block validates, then commits the transaction (by returning an action to perform in the IO context)
    - 一个TVar需要一个STM上下文，但这些只在原子{...}块中可用。不能在事务之外更新TVar，所以不能破坏原子性准则 - Haskell不允许通过指针无限制地访问堆，所以不能颠覆 •	A TVar requires an STM context, but these are only available in an atomic {…} block; can’t update a TVar outside a transaction, so can’t break atomicity guidelines – Haskell doesn’t allow unrestricted heap access via pointers, so can’t subvert
- I/O不能在原子性的{...}块内执行•	I/O cannot be performed within an atomic {…} block
  - 事务不在IO上下文中•	The transaction is not in the IO context

# 整合其他语言：Integration into Other Languages

> 如果你是一个Haskell程序员，原子事务是非常强大的。但它们依赖于类型系统中不被普遍或广泛理解的特性，以提供安全性。将原子事务整合到更多的主流语言中并不简单。大多数语言不能强制使用纯函数，或参考透明度。大多数语言不能限制I/O的使用，也不能跟踪内存访问以避免副作用。If you’re a Haskell programmer, atomic transactions are very powerful. But they rely on features of the type system that are not commonly or widely understood, in order to provide safety. Integrating atomic transactions into more mainstream languages is not straightforward. Most languages can’t enforce the use of pure functions, or referential transparency. Most languages can’t limit the use of I/O, and can’t track memory accesses to avoid side effects.

- 原子事务Haskell非常强大--但要依靠类型系统来确保安全组合和重试 •	Atomic transactions Haskell are very powerful – but rely on the type system to ensure safe composition and retry
- 集成到主流语言中是困难的 •	Integration into mainstream languages is difficult
  - 大多数语言不能强制使用纯函数 •	Most languages cannot enforce use of pure functions
  - 大多数语言不能限制I/O和副作用的使用 •	Most languages cannot limit the use of I/O and side effects
  - 事务内存可以在没有这些的情况下使用，但是需要程序员的纪律来确保正确性--并且有无声的失败模式 •	Transaction memory can be used without these, but requires programmer discipline to ensure correctness – and has silent failure modes
- 不清楚事务性方法是否可以推广到其他语言 •	Unclear if the transactional approach generalises to other languages

# Reading

http://www.cmi.ac.in/~madhavan/courses/pl2009/reading-material/harris-et-al-cacm-2008.pdf

> 当然，原子事务可以在没有这些限制的情况下使用，但这样做需要程序员有纪律来确保正确性。程序员必须避免副作用，并避免I/O，而不需要编译器的帮助。如果程序员做得不正确，就会引入难以发现的错误。而这就是风险所在。只有当语言和运行时能够控制I/O和控制副作用时，原子事务才是安全的。而唯一拥有必要机制来安全地做到这一点的语言是Haskell。目前还不清楚事务性方法是否可以推广到其他语言。 Atomic transactions can be used without these restrictions, of course, but doing so requires the programmer to have discipline to ensure correctness. The programmer has to avoid side effects, and avoid I/O, without help from the compiler. And if the programmer does this incorrectly, difficult to find bugs get introduced. And this is the risk. Atomic transactions are only safe if the language and the runtime can control I/O and control side effects. And the only language that has the necessary mechanisms to do that safely, is Haskell. It’s not clear that the transactional approach generalises to other languages.
> 原子事务是一个有趣的想法。在Haskell中，它们提供了一种引人注目的体验。它们避免了并发代码中由于竞赛条件、锁定和死锁而产生的问题。而且它们允许函数的任意组合，而不必担心结果是否被正确锁定。不过，在其他语言中，这些好处就不那么明显了。对我来说，不清楚的是，这是否是Haskell做了正确的事情的一个例子，如果我们想要安全的并发代码，世界上的其他人只需要学习用纯函数式编程。或者说，Haskell开发了一种理论上很有趣的方法，但在主流语言中却永远不实用。幻灯片中链接的论文详细地谈论了原子事务以及它们是如何工作的 Atomic transactions are an interesting idea. In Haskell, they offer a compelling experience. They avoid problems due to race conditions, locking, and deadlocks in concurrent code. And they allow arbitrary composition of functions without having to worry whether the result is correctly locked. In other languages, though, the benefits are less clear cut. And what’s not clear to me, is whether this is an example of Haskell doing the right thing, and the rest of the world just needs to learn to program in a pure functional style if we want safe concurrent code. Or if Haskell has developed an approach that’s interesting in theory, but that will be forever impractical in mainstream languages. The paper linked from the slide talks about atomic transactions and how they work in detail.

- 事务性内存是一种现实的技术吗？•	Is transactional memory a realistic technique?
- 它对纯功能语言的要求，以及对I/O的控制，是否限制了它成为一个研究玩具？•	Do its requirements for a purely functional language, with controlled I/O, restrict it to being a research toy?
- 在更传统的语言中，能从事务性内存中获得多大的好处？•	How much benefit can be gained from transactional memory in more traditional languages?

# ================

# 3消息传递系统：Message Passing Systems

讲座的第三部分从交易开始，讨论消息传递作为一种并发模型。它介绍了基于角色的编程，以及各种风格的消息传递系统，使用了Scala+Akka和Rust的例子。它展示了消息传递如何为并发编程提供一个自然的模型，这对那些有编写网络应用的人来说是很熟悉的，但讨论了与事务相比所提供的有限保证。

# 消息传递系统-定义：Message Passing Systems

- 系统的结构是一组交流的进程，即行动者，没有共享的可改变的状态。•	System is structured as a set of communicating processes, actors, with no shared mutable state 【**消息传递系统的目标是，系统被结构化为一组交流的进程。这些进程往往被称为行动者，它们的结构使它们不共享可改变的状态** the goal of a message passing system is that the system gets structured as a set of communicating processes. These tends to be known as actors, and they're structured such that they shared no mutable state.】
- 【**行为体通过向对方发送消息进行通信。而发送消息的行为是这些系统中唯一可以发生通信的方式。没有共享的内存，也没有共享的可改变的状态。这种系统中的消息通常被要求是不可改变的，它们在被发送后不能改变。在这些系统中，数据在概念上是在进程之间复制的，尽管在实践中它是通过复制一个引用来实现的。但是，由于数据是不可变的，这没有实际的区别；你正在交换不能改变的消息** The actors communicate by sending messages to each other. And the act of sending a message is the only way communication can occur in these systems. There's no shared memory, there's no shared mutable state. The messages in such systems are generally required to be immutable, they can't change after they've been sent. The data is conceptually copied between processes in these systems, although in practice it’s implemented by copying a reference. But, since the data is immutable, this has no practical difference; you're exchanging messages that can’t change.】
  - 所有的通信都是通过信息的交换进行的•	All communication via exchange of messages
    - 消息通常被要求是不可变的--在概念上，数据在进程之间被复制。•	Messages are generally required to be immutable – data conceptually copied between processes
    - 一些系统使用线性类型来确保消息在发送后不被引用，允许安全地传输可变数据•	Some systems use linear types to ensure messages are not referenced after they are sent, allowing mutable data to be safely transferred
- 实施•	Implementation
  - 在单个系统内的实现通常用共享内存和锁来构建，传递对消息的引用--依赖于对消息传递实现的正确锁定•	Implementation within a single system usually built with shared memory and locks, passing a reference to the message – rely on correct locking of message passing implementation 【**另外，一些系统使用一种称为线性类型的技术，本质上是所有权跟踪，以确保消息在被发送后不会被引用。这使得可变数据可以被安全地传输。如果你有一个共享内存的单一系统，实现的方式是使用线程和锁。你在线程之间传递一个对消息的引用。而这显然依赖于通信机制的正确实现，以及正确的锁定。我认为，这样做的好处是，只需要做一次就可以了** Alternatively, some systems using a technique known as linear types, essentially ownership tracking, to ensure that messages are not referenced after they've been sent. This allows mutable data to be safely transferred. The way this is implemented, if you have a single system with shared memory, is using threads and locks. You're passing a reference to the message between threads. And this obviously relies on the communication mechanism being implemented correctly, and being correctly locked. The benefit, I think, comes because that only has to be done once.】
  - 通过向网络通道发送消息，可以很容易地进行分发--运行时需要知道网络的情况，但应用程序可以不知道系统是分发的。•	Trivial to distribute, by sending the message down a network channel – the runtime needs to know about the network, but the application can be unaware that the system is distributed 【**你必须实现一次交换消息的锁，作为系统的一部分，但然后每一个建立在其上的系统都会免费获得正确锁定的通信机制。当然，这些系统有一个优势，那就是它们很容易分发。因为你在系统之间传递消息，而这些消息要么是不可改变的，要么是运行时，即类型系统，确保所有权被跟踪，并强制它们被发送，所以只要通过套接字将消息发送到网络上的另一个节点，而不是在单个系统内通过共享内存传递，就可以非常容易地制造一个分布式系统。因此，运行时显然需要意识到它是分布式的，但有可能建立这些应用程序，使它们可以在网络上的多个节点上运行，而应用程序并不知道它们是分布式的** You have to implement the locks to exchange messages once, as part of the system, but then every system which is built on top of that gets the correctly locked communication mechanism for free. And these systems have the advantage, of course, that they’re trivial to distribute. Since you're passing messages between systems, and those messages are either immutable, or the runtime, the type system, ensures that ownership is tracked and enforces that they’re sent, it becomes possible to make a distributed system very easily just by sending the messages down a socket to another node on the network, rather than passing them by shared memory within a single system. So the runtime obviously needs to be aware that it's distributed, but it's possible to build these applications, such that they can run across multiple nodes on the network, and such that the application is unaware that they are distributed.】

# 消息处理：Message Handling

![](/static/2022-05-08-00-44-43.png)

- **接收者对消息进行模式匹配**•	Receivers pattern match against messages
  - 针对消息类型进行匹配，而不仅仅是值•	Match against message types, not just values
  - 类型系统可以确保详尽的匹配•	Type system can ensure an exhaustive match
- **消息排队等待处理**•	Messages queued for processing
  - 调度器管理一个线程池，为行为体的接收者组件服务•	Dispatcher manages a thread pool servicing receiver components of the actors
  - 接收者在消息处理循环中操作--单线程，不关注并发性•	Receivers operate in message processing loop – single-threaded, with no concern for concurrency
  - 已发送的消息被其他角色排队处理•	Sent messages enqueued for processing by other actors

> **如果你看一下行为体是如何实现的，往往会有一个已经到达并等待处理的消息队列。队列是同步发生的地方；队列数据结构上有一个锁，正在发送消息的其他行为体得到队列上的锁，并将他们的消息添加到队列中。在队列头部的消息被出队。它被送到一个调度器，调度器会查看消息的类型，并与类型进行模式匹配**。The implementation of one of these, if you look at how an actor is implemented, tends to have a queue of messages which have arrived and are waiting to be processed. The queue is where synchronisation happens; there's a lock on the queue data structure and processes, other actors, which are sending messages, get a lock on the queue and append their messages to the queue. The message at the head of the queue is de-queued. It goes to a dispatcher, which then looks at the type of the message and pattern matches against the type.
> **然后，接收进程根据收到的消息类型执行不同的操作。当这一切完成后，它只是循环往复，从队列中拉出下一条消息，并只是在一个循环中执行，处理一条又一条的消息**。 And the receiving process then executes a different action depending on what type of message has been received. And when that's done, it just loops around and pulls the next message off the queue, and just executes in a loop, processing message, after message, after message.
> **如果它需要与系统中的其他角色通信，它可以向外发送消息，这些消息被排入队列，由其他角色处理。那么，整个系统就像一组行动者一样进行，每个行动者在一个循环中处理消息，将消息发送给其他行动者。它看起来很像一个联网的系统；很像一个联网的服务器。它处理消息并发送回复**。 If it needs to communicate with the other actors in the system, it can send messages out, and they get queued up to be processed by the other actors. The entire system, then, proceeds as a set of actors, each processing messages in a loop, sending messages out to other actors. It looks a lot like a networked system; a lot like a networked server. It processes messages and it sends replies.

# 消息传递类型：Types of Message Passing

- 几个不同的消息传递系统设计。•	Several different message passing system designs:
  - 同步与异步•	Synchronous vs asynchronous
  - 静态或动态类型•	Statically or dynamically typed
  - 直接或间接的消息传递•	Direct or indirect message delivery

- 每种设计都有优势和劣势•	Each has advantages and disadvantages

> 你可以用很多不同的方式来构造这些系统。可以建立基于角色的消息传递系统，以同步或异步的方式运行；可以使它们成为静态或动态类型；或者它们直接向角色传递消息，或通过通道间接传递。而这些不同的方法都有自己的优势和劣势。 There are lots of different ways in which you can structure these systems. It’s possible to build actor-based message passing systems that operate in a synchronous or an asynchronous manner; it’s possible to make them statically or dynamically typed; or that they deliver messages directly to actors, or indirectly via channels. And each of these different approaches has its own advantages and its own disadvantages.

# 消息传递类型-交互模型：Interaction Models

- **消息传递可以涉及发送方和接收方之间的会合**•	Message passing can involve rendezvous between sender and receiver
  - 同步消息传递模式--发送方等待接收方的到来•	A synchronous message passing model – sender waits for receiver
- **或者，通信可以是异步的**•	Alternatively, communication may be asynchronous
  - 发送者在发送消息后立即继续•	The sender continues immediately after sending a message
  - 信息被缓冲，以便稍后传递给接收者•	Message is buffered, for later delivery to the receiver
  - 可以通过等待回复来模拟同步会合。•	Synchronous rendezvous can be simulated by waiting for a reply

> 通信有可能是同步的，也有可能是异步的。消息传递有可能涉及发送方和接收方之间的会合。一个同步的消息交换。在这种情况下，发送方等待接收方在发送消息时变得可用。或者，如果接收方先到达会合点，它就等待发送方。而这有一个好处，就是使两者的时间一致。你知道两者都是可用的，发送方和接收方都是可用的，在通信的时候。It’s possible for the communication be synchronous or asynchronous. It’s possible that message passing involves a rendezvous between the sender and the receiver. A synchronous message exchange. In this case, the sender waits for the receiver to become available when the message is sent. Or, if the receiver gets to the rendezvous first, it waits for the sender. And this has the benefit of making the two time-aligned. You know that both are available, both sender and receiver are available, at the point of communication.
> 另外，通信也可以是异步的。发送者可以发送一个消息并继续，而不需要等待接收者接收。在这种情况下，信息在某处被缓冲，并最终被传递给接收者。而且，在某些方面，这是有利的，因为发送方可以在等待接收方处理消息时继续做其他工作。但是，这有一个风险，即接收方以某种方式失败了，没有处理信息，或者处理信息的速度不够快。你可以得到一个积压的消息的积累。 Alternatively, the communication can be asynchronous. The sender can send a message and continue, without waiting for the receiver to receive it. In this case, the message is buffered up somewhere, and eventually gets delivered to the receiver. And, in some ways, that's advantageous because the sender can keep doing some other work while waiting for the receiver to process the message. But it has the risk that the receiver has somehow failed, and is not processing messages, or it's not processing messages quickly enough. You can get a backlog of messages building up.
> 而在某种程度上，这可能是有问题的。你不希望发送方在接收方不处理消息的情况下继续将消息放入队列。它希望以某种方式意识到失败，意识到延迟的存在。而这些系统会变得不平衡。如果系统中的某一部分没有跟上，就没有反作用力来逐渐减慢系统的速度。 And to some extent that can be problematic. You don't want the sender to keep putting messages into the queue if the receiver isn't processing them. It wants to somehow be aware of the failure, of the delays. And these systems can get unbalanced. There's no back-pressure to gradually slow the system down, if one part of it isn't keeping up.
> 因此，有同步交会的系统也许有优势，或者有有限的缓冲容量，超过这个容量，交会就变成了同步。只是为了提供背压，以确保整个系统以其最慢的组件的速度运行。当然，如果你有一个异步系统，你可以通过等待回复来模拟一个同步系统，这样你就知道消息被收到了。 So there are perhaps advantages to systems where there’s a synchronous rendezvous, or where there’s a limited amount of buffering capacity and, beyond that, the rendezvous become synchronous. Just to provide back-pressure, to make sure the whole system is operating at the speed of it’s slowest component. Of course, if you have an asynchronous system, you can simulate a synchronous system by waiting for a reply, so you know the message was received.

# 消息传递类型-通信类型：Typed Communication

不同的系统也会围绕消息的类型做出不同的选择 Different systems also make different choices around the typing of messages.

- **静态类型的通信**•	Statically-typed communication
  - 明确定义可以传输的消息类型•	Explicitly define the types of message that can be transferred
  - 编译器检查接收者是否能处理它能接收的所有消息 - 稳健性，因为接收者被保证能理解所有消息•	Compiler checks that receiver can handle all messages it can receive – robustness, since a receiver is guaranteed to understand all messages
- **动态类型的通信**•	Dynamically-typed communication
  - 通信媒介传递任何时间的消息；接收者使用对所接收的消息类型的模式匹配来确定它是否能对消息做出反应•	Communication medium conveys any time of message; receiver uses pattern matching on the received message types to determine if it can respond to the messages
  - 如果接收器收到它不理解的消息，有可能导致运行时错误•	Potentially leads to run-time errors if a receiver gets a message that it doesn’t understand

> 构建静态类型的系统是可能的，在这种系统中，可以发送到特定角色的消息的类型被很好地定义并在类型系统中被检查，由编译器检查。在这些类型的系统中，编译器会检查接收器是否能够处理它所能接收的所有可能的消息。而且，如果系统不能处理不同的消息，它就不会被编译。而且，在某些方面，这提供了稳健性。一个接收器被保证能够理解它所收到的所有消息。 it’s possible to build statically typed systems, where the types of the messages which can be sent to a particular actor are well defined and checked in the type system, checked by the compiler. In these types of systems, the compiler checks that a receiver can handle all the possible messages it can receive. And the system won't compile if it can't handle the different messages. And, in some ways, this provides robustness. A receiver is guaranteed to be able to understand all the messages it receives.
> 另外，系统可以更加动态地类型化，通信媒介、通信渠道、消息传递系统传达消息的类型，接收者在这些类型上进行模式匹配，并试图找出它是否可以响应消息。如果类型化是非常动态的，这就有可能出现运行时的故障，当然。有可能向一个接收器发送它不理解的消息。 Alternatively, the system can be more dynamically typed, where the communication medium, the communication channel, the message passing system, conveys the type of the message and the receiver pattern matches on those types, and tries to figure out if it can respond to the messages. If the typing is very dynamic, this has the potential for runtime failures, of course. It's possible to send a message to a receiver which it doesn't understand
>
> * 所以这些类型的系统倾向于有一个catch-all在里面，并且它们倾向于指定接收器在收到未知的消息类型时做什么。而这些也许更灵活。你不需要一下子就把系统发展起来。而且有可能建立能够选择性地处理某些类型的消息的系统，而只是丢弃他们不理解的消息。因此，这有可能使系统更容易进化。. So these types of system tend to have a catch-all in there, and they tend to specify what the receiver does if it receives an unknown message type. And these are perhaps more flexible. You don't need to evolve the system all at once. And it's possible to build systems that can optionally handle certain types of messages, and just discard messages they don’t understand. So this may potentially make a more evolvable system.
> * 而且，特别是对于分布式系统来说，这有可能为系统的部分升级和系统的发展提供灵活性。但这确实意味着你必须考虑如何处理未知的消息，并有运行时失败的风险。 And, especially for distributed systems, this potentially offers the flexibility to upgrade the system in parts, and to evolve the system. But it does mean you have to think about how to handle unknown messages, and have the risk of runtime failures.

# 消息传递类型-Naming

- 消息是在命名的进程之间发送，还是通过通道间接发送？•	Are messages sent between named processes or indirectly via channels?
  - 一些系统直接将消息发送到角色（进程），每个角色都有自己的邮箱。•	Some systems directly send messages to actors (processes), each of which has its own mailbox
  - 其他系统使用显式信道，通过信道将消息间接发送到邮箱。•	Others use explicit channels, with messages being sent indirectly to a mailbox via a channel

- 显式通道需要更多的管道，但发送方和接收方之间额外的间接性可能对不断发展的系统很有用。•	Explicit channels require more plumbing, but the extra level of indirection between sender and receiver may be useful for evolving systems
- 显式信道是为静态类型的消息定义通信协议的自然场所。•	Explicit channels are a natural place to define a communications protocol for statically typed messages

> 你还需要考虑消息是否在命名的进程之间直接发送，消息是否直接发送到角色，或者是否通过一些通信渠道间接发送 You also need to think about whether messages are being sent directly between named processes, whether messages being sent directly to an actor, or whether they're being sent indirectly via some communications channel.
>  有些系统的安排是这样的，它们直接向角色发送消息。你得到一个行为体的引用，你可以直接向该行为体发送消息。 Some of these systems are arranged such that they directly send messages to actors. You get a reference to the actor, and you can directly message that actor
> 其他的则有通道的概念，你得到一个对通信通道的引用，然后你把消息放入该通道。接收者将它们从通道中取出，从通信链路中取出，并将它们放入其邮箱进行处理。. Others have this idea of channels, where you get a reference to a communications channel, and you put messages into that channel. And the receiver takes them out of the channel, out of the communications link, and puts them into its mailbox for processing.
>  显式通道的使用在某些方面增加了开销。它要求你明确地把系统放在一起，并把通信通道连接到发送者和接收者。但是，它提供了一个额外的间接性。这可能对系统的发展很有帮助，因为你可以改变接收器而不需要让发送者知道接收器已经改变。或者，同样地，你可以改变发送者而不需要接收者知道。而且，只要通信链路在那里，你就可以改变连接到终端的东西。而这对系统的发展是很有帮助的。当你改变接收过程时，你不需要告诉所有的发送者。 The use of explicit channels adds overhead in some ways. It requires you to explicitly plumb the system together, and connect up the communications channels to the senders and receivers. But, it provides an extra level of indirection. And this can potentially be useful for evolving the system, in that you can change the receiver without the senders having to know that the receiver has changed. Or, similarly, you can change the senders without the receiver having to know. And, as long as the communications link is there, you can change what's connected to the endpoints. And that potentially is useful to evolve the system. You don't have to tell all the senders when you change the receiving process
> 显式通道也可能是一个定义通信协议的自然场所，并指定可以传输的消息的类型，所以它们可能有这样的优势。当然，问题是复杂性，以及必须把系统放在一起，所以也有一些开销. And explicit channels are also perhaps a natural place to define a communications protocol, and to specify the types for messages that can be transferred, so they perhaps have an advantage that way. Though, of course, the issue is complexity, and having to plumb the system together, so there’s some overhead too.

# 消息传递-现有实现：Implementation

- **消息传递开始看到广泛的部署，有两种广泛使用的架构**。•	Message passing starting to see wide deployment, with two widely used architectures:
- **直接传递的动态类型**•	Dynamically typed with direct delivery
  - Erlang编程语言(https://www.erlang.org/)
  - Scala编程语言（http://www.scala-lang.org）和Akka库（http://akka.io）。
  - 动态类型化--任何类型的消息都可以被发送到任何接收方•	Dynamically typed – any type of message may be sent to any receiver
  - 消息**直接发送到命名的角色**，而不是通过通道•	Messages sent directly to named actors, not via channels
  - 两者都在网络系统中提供透明的进程分配•	Both provide transparent distribution of processes in a networked system
- **静态类型的，有明确的通道**•	Statically typed, with explicit channels
  - Rust编程语言（https://www.rust-lang.org/）
  - 使用通过**显式通道传递的异步静态类型的消息**•	Use asynchronous statically typed messages passed via explicit channels

# Scala+Akka例子

![](/static/2022-05-08-01-15-38.png)

* 行为体包括一个接收循环，在收到消息时对其作出反应The actor comprises a receive loop that reacts to messages as they’re received
* 完整的程序是一个交换信息的行为体的集合。Complete program is a collection of actors that exchange messages

> 因此，让我们来看看这两种方法各自的一个例子。所以，第一个例子是用Scala编程语言写的，使用一个被称为Akka的角色系统。Scala是一种功能性语言，在Java虚拟机上运行。而且，我们在这里看到，在幻灯片的底部，我们看到main对象正在被创建。它说 "object Main extends App"。这是系统中的main对象，相当于main函数。So let's look at an example of each of the two approaches. So, the first one is an example written in Scala programming language, using an actor system known as Akka. And Scala is a functional language, which runs on the Java Virtual Machine. And, what we see here, at the bottom of the slide, we see the main object being created. It says “object Main extends App”. This is the main object in the system, the equivalent of the main function.
> 这创建了一个运行时的角色。然后它创建了一个角色。它说 "val helloActor = runtime.actorOf"，这就创建了一个HelloActor类型的角色，并给它一个名字，把它分配给一个不可变的变量helloActor。 And this creates an actor runtime. And then it creates an actor. It says “val helloActor = runtime.actorOf”, and this creates an actor of type HelloActor, and it gives it a name, and it assigns this to an immutable variable helloActor.
> 然后它向它发送一些消息。语法中的角色名称、感叹号和消息是Akka用来发送消息的语法。这里首先发送两个消息 "hello"，然后发送 "buenos dias"，给HelloActor。 And then it sends it some messages. And the syntax with the actor name, and the exclamation mark, and the message is the syntax Akka uses to send messages. And this sends the two messages firstly “hello”, and then secondly “buenos dias”, to the HelloActor.
> 我们在幻灯片顶部看到的代码，HelloActor类，定义了接收这些消息的角色的全部内容。它有一个接收方法。语法 "def receive ="是定义了一个方法。这个方法只是对它收到的消息类型进行模式匹配，所以它就像Rust中的匹配语句。 And the code we see at the top of the slide, the class HelloActor, defines the entirety of the actor which is receiving those messages. It's got to receive method. The syntax “def receive =” is defining a method. And this method just pattern matches on the types of messages it receives, so it's like a match statement in Rust.
> 它有一个案例，如果它收到字符串 "hello"，它就打印 "hello back at you"，如果它收到任何其他类型的消息，它就说 "huh？"。 it's got a case where, if it receives the string “hello” it prints “hello back at you”, and if it receives any other type of message it just says “huh?”.
> 角色只是在一个循环中运行。它只是不断地接收这些消息并处理它们。它可以通过模式匹配的方式获得消息对象，如果它想的话，这就允许它发送一个响应。 And the actor just runs in a loop. It just continually receives these messages and processes them. And it can pattern match in a way that gets the message object, which allows it to send a response if it wants.
> 它可以在行为体对象中存储数据，其中可以包括对它所发送的其他行为体的引用，这使得它可以建立起更复杂的通信模式。一切都非常动态，但它的开销很低，在语法上也很干净。 And it can store data in the actor object, and that can include references to other actors which it’s been sent, and that allows it to build up more complex communication patterns. And everything’s very dynamic but it's quite low overhead, it’s quite syntactically clean.

# Rust例子

在这个例子中，我们也可以看到你如何在Rust中做到这一点。在这个例子中，我们有一个主函数，它创建了一个通道，生成了一个线程，并在它们之间发送了一条消息。所以我们来看看这个。 We can also see, in this example, how you might do it in Rust. In this case, we have a main function which creates a channel, spawns a thread, and sends a message between them. So let's walk through this.

```rust
use std::sync::mpsc::channel; use std::thread;

fn main() {
  let (tx, rx) = channel();

  thread::spawn(move|| 
    { let _ = tx.send(42);
  });

  match rx.recv() 
  { Ok(value) => {
    println!(“Got {}”, value);
  }
  Err(error) => {
    // An error occurred…
    }
  }
}
```

![](/static/2022-05-08-01-21-29.png)
![](/static/2022-05-08-01-22-49.png)

> 在这个例子中，我们也可以看到你如何在Rust中做到这一点。在这个例子中，我们有一个主函数，它创建了一个通道，生成了一个线程，并在它们之间发送了一条消息。所以让我们来看看这个。首先，我们有一个函数，main()，这个函数保存了系统的全部状态，这在Rust程序中是很正常的。main()函数做的第一件事是创建一个通道。通道是在标准库中定义的，是Rust的线程间通信机制。而通过调用channel()，它会返回给你一个该通道的发送端和接收端的元组。通道是单向的，你向一端发送，它就从接收端出来。而main()函数现在对通道的两端都有引用。 We can also see, in this example, how you might do it in Rust. In this case, we have a main function which creates a channel, spawns a thread, and sends a message between them. So let's walk through this. To start with, we have a function, main(), and this holds the entire state of the system, as is normal in Rust programs. The first thing that the main() function does is create a channel. The channel is defined in the standard library, and is the inter-thread communication mechanism for Rust. And by calling the channel() call, it returns you a tuple of the transmitting and receiving ends of that channel. The channels are unidirectional, and you transmit into one end, and it comes out of the receiving end. And the main() function now has references to both ends of channel.

![](/static/2022-05-08-01-24-45.png)

> 我们调用 thread::spawn()。这是在 Rust 中创建新线程的方式。而且，这再次来自标准库，并且线程 spawn() 调用创建了一个新的执行线程。 We call thread::spawn(). This is the way you create a new thread in Rust. And, again, this comes from the standard library, and the thread spawn() call creates a new thread of execution.

---

![](/static/2022-05-08-01-28-43.png)

> 被该线程执行的是其参数的内容。它所传递的是所谓的闭包。它被传递了一个代码块，它从环境中捕获了必要的变量。正如我们在幻灯片底部看到的那样，有两种方法来编写这样的匿名闭包。What gets executed by that thread is the contents of its argument. It's passed what’s known as a closure. It's passed a block of code, which captures the necessary variables from its environment. There’s two ways of writing an anonymous closure like this, as we see in the bottom of the slide.
> 你可以只在栏内指定参数，然后再指定代码。在这种情况下，闭包会借用其环境。它借用其参数的值，以及它所引用的任何变量，都来自于包围的函数。 You can just specify the arguments within the bars, and then the code. And, in that case, the closure borrows its environment. It borrows the values of its arguments, and any variables it references, from the enclosing function
> 或者你可以通过说 "move "来定义它，接着是参数栏，然后是代码。这样就取得了它的参数的所有权，它从环境中取得了它需要的值的所有权。所以它把数据的所有权转移给了闭包。. Or you can define it by saying “move”, followed by the arguments in bars, followed by the code. And that takes ownership of its arguments, it takes ownership of the values it needs from the environment. So it transfers ownership of the data to the closure.
> 现在，在这个特殊的例子中，我们指定了一个移动闭包，所以它正在取得所有权。这里有两个条，它们之间没有参数，因为这个特殊的闭包不接受任何明确的参数。 Now, in this particular case, we specify a move closure, so it's taking ownership. And there are the two bars, with no arguments between them, because this particular closure doesn't take any explicit arguments.
>  闭包的主体只是大括号中的代码，其中写着 "let _ = tx.send(42)"。你可以看到它引用了tx的值，它被定义在main()函数中。所以它从环境中引用了一个值。而且，因为它是一个移动闭包，所以它取得了它的所有权。所以值tx的所有权已经被转移到这个闭包中，并被传递给thread::spawn()调用。 And the body of the closure is just code within the braces, where it says “let _ = tx.send(42)”. And you see this references the value of tx, which was defined in the main() function. So it's referenced a value from its environment. And, because it's a move closure, it takes ownership of that. So the ownership of the value tx has been moved into this closure, and that's been passed to the thread::spawn() call.
> 因此，这已将 tx 的所有权转移到另一个线程中。所以，此时，我们有两个执行线程正在运行。我们已经有了主线程，并且我们有了已经产生的新线程。并且已经产生的线程已经获得了变量 tx 的所有权，因此它可以访问通道的传输描述符。但是接收描述符仍然保留在 main() 函数中。它调用 tx.send()。它将数字 42 沿该通道传输，并将返回值分配给下划线，因此它不等待响应。 So this has moved the ownership of tx into the other thread. So, at this point, we have two threads of execution running. We've got the main thread, and we've got the new thread which has been spawned. And the thread which has been spawned has taken ownership of the variable tx, so it's got access to the transmit descriptor of the channel. But the receive descriptor still remains with the main() function. And it calls tx.send(). It transmits the number 42 down that channel, and it assigns the return value to underscore so it's not waiting for a response.

---

![](/static/2022-05-08-01-37-49.png)

> 这就把值传回了主线程，沿着通道。在主线程中，你在rx变量上调用recv()，即通道的接收方，并对结果进行模式匹配。如果你得到一个成功的值，你可以看一下被发送过来的值的内容，然后处理它。或者它可能出错，这取决于传输过程中是否出了问题。And this passes the value back to the main thread, down the channel. Back in the main thread, you call recv() on the rx variable, the receive side of the channel, and you pattern match on the result. And if you get a success value, you can look at the contents of the value which was sent over, and process that. Or it can error, depending if something went wrong with the transmission.
> 这是个比Scala更明确的过程。我们通过创建通道明确地把发送方和接收方连接在一起。 It’s a much more explicit process than in Scala. We’re explicitly plumbing together the sender and the receiver by creating the channel.

# 权衡：Trade-offs

- 这两种方法的行为是完全不同的。•	The two approaches behave quite differently:
- Scala+Akka让弱耦合的进程通过**异步和动态类型**的消息进行通信。•	Scala+Akka let weakly coupled processes to communicate via asynchronous and dynamically typed messages:
  - 富有表现力、灵活和可扩展的角色模型•	Expressive, flexible, and extensible actor model
  - 通过独立进程处理错误的强大框架•	Robust framework for error handling via separate processes
  - 通过动态行为体的插入，相对容易升级运行中的系统•	Relative ease of upgrading running systems via dynamic actor insertion
  - 检查是在运行时进行的，因此对健壮性的保证是概率性的•	Checking happens at run time, so guarantees of robustness are probabilistic
- **Rust使用静态类型的消息传递，提供编译时的检查，即一个进程可以响应消息**•	Rust uses statically typed message passing provides compile-time checking that a process can respond to messages
  - 但是，需要更多的管道来连接通道•	But, requires more plumbing to connect channels
  - 有更明确的错误处理•	Has more explicit error handling
  - 通常的静态类型与动态类型的辩论•	The usual static vs. dynamic typing debate

> Scala和Akka采取的方法可以让你把弱类型的进程结合起来。它们可以以非常异步和非常动态的方式进行通信。它非常有表现力，非常灵活，而且它有一个相当有趣的错误处理模型，使用单独的进程进行错误处理，我们稍后会讨论这个问题。它使升级系统变得相对容易，根据需要动态地将角色插入系统中，建立能够处理可选消息的系统。检查发生在运行时，因此你可以得到正确性的概率保证。系统可以在运行时失败，因为不了解发送消息。 The approach taken in Scala and Akka lets you couple weakly-typed processes together. And they can communicate in a very asynchronous and very dynamic way. It’s very expressive, it’s very flexible, and it's got a reasonably interesting error handling model using separate processes for error handling which we'll talk about later. And it makes it relatively easy to upgrade the system by dynamically inserting actors into the system as needed, by building systems which can which can deal with optional messages. And the checking happens at runtime, and so you get probabilistic guarantees of correctness. The system can fail at runtime, due to not understand sending messages. 
> 另一方面，Rust是静态类型的，它提供了编译时的检查，即一个进程可以响应它所发送的所有消息。但是，它更明确，它需要更多的管道将通道连接在一起。而且它需要更明确的错误处理，所以可能会有更多的开销。从本质上讲，这就是通常的静态与动态类型的争论，但在你所交换的消息类型中进行了讨论。 Rust, on the other hand, is very statically typed, and it provides compile time checking that a process can respond to all the messages it’s sent. But, it's more explicit, it requires more plumbing to connect the channels together. And it needs more explicit error handling, so there's perhaps more overhead there. Essentially, is the usual static versus dynamic typing debate, but playing out in types of messages you’re exchanging.

# ================

# 4竞赛条件：Race Conditions

本讲座的最后部分讨论了竞赛条件。它介绍了什么是竞赛条件，为什么它们是有问题的，以及它们如何在消息传递和共享内存系统中发生。

# 竞赛条件定义

- 当一个系统的行为取决于不同行动的相对时间时，或者当一个共享值在没有协调的情况下被修改时，就会出现竞赛条件。•	A race condition can occur when the behaviour of a system depends on the relative timing of different actions – or when a shared value is modified without coordination
- 引入非决定性行为和难以调试的问题•	Introduces non-deterministic behaviour and hard-to-debug problems
- 难以预测程序行为的确切时间•	Difficult to predict exact timing of program behaviour
- 难以预测异步的、不受控制的、对共享值的修改的影响•	Difficult to predict effects of asynchronous, uncontrolled, modification to shared values

> 当一个系统的行为取决于不同的行动、不同的事件的相对时间，或者当一个共享的值被修改而没有在不同的线程、系统的不同部分之间进行协调时，就会出现竞赛条件。而且它在程序中引入了非确定性行为。很难预测一个程序的确切时间行为。很难预测如果多个线程异步地修改一个共享值会发生什么。因此，你会得到难以调试的问题，以及无法从整个系统中预测的行为。what is a race condition? A race condition can occur when the behaviour of a system depends on the relative timing of different actions, different events, that can occur, or when a shared value is modified without coordination between the different threads, the different parts of the system, which are modifying that value. And it introduces non deterministic behaviour into the program. It's difficult to predict the exact timing behaviour of a program. It’s difficult to predict what happens if multiple threads asynchronously modify a shared value. And, as a result, you get hard to debug problems, and behaviour which is not predictable from the system as a whole.
> 从根本上说，有两种类型的竞赛可以发生。在消息传递系统中，由于消息到达的顺序，你可以得到竞赛，而在共享内存系统中，你可以得到，由于修改值而引起的竞赛。 There are two types of race that can fundamentally happen. In message passing systems, you can get races due to the order in which messages arrive, and in shared memory systems you can get, in addition, races due to modification of values.

# 消息竞赛：Message Races

![](/static/2022-05-08-12-48-35.png)

- **在消息传递系统中，可以从多个发送方接收消息**•	In message passing systems, messages can be received from multiple senders
- **运行时确保接收者按照收到的顺序依次处理消息，但由于系统和网络负载、外部事件等原因，收到的顺序可能有所不同**。•	Runtime ensures receiver processes messages sequentially, in the order they are received, but order of receipt can vary due to system and network load, external events, etc.
  - 当消息以不可预知的顺序到达时，就会出现**竞赛条件**。•	A race condition occurs when messages arrive in unpredictable order
  - 当一个循环形成时，就会出现**死锁**，行为者互相等待消息。•	A deadlock occurs when a cycle forms, with actors waiting for messages from each other
- 构建通信模式以避免•	Structure communication patterns to avoid

> 在消息传递系统中，当收到来自多个发送者的消息到一个特定的接收者时，就会出现竞赛条件。In message passing systems, the race condition can occur when messages are received from multiple senders to a particular receiver
> 在这些类型的系统中，运行时确保接收方按顺序处理消息，并按照接收的顺序处理消息。但是，不幸的是，接收消息的顺序可能有所不同。. In these types of systems, the runtime ensures that the receiver processes the messages sequentially, and processes the messages in the order that they’re received. But, unfortunately, the order in which the messages are received can vary. 
> 由于系统负载，由于网络负载，由于调度过程中的细节，如果涉及到网络，由于拥堵控制或数据包丢失，消息接收的顺序可能会有所不同。And the order the messages are received can vary because of system load, because of network load, because of details in the scheduling processes, if a network is involved, because of congestion control or packet loss, for example.
> 因此，如果你有来自多个发送方的信息到达接收方，这些信息可能以不可预测的顺序到达。你并不总是能保证来自发送方一的信息一定会在来自发送方二的信息之前到达。 And, as a result, the messages, if you have messages arriving at receiver from multiple senders, can arrive in unpredictable order. You’re not always guaranteed that a message from sender one will necessarily arrive before a message from sender two.
> 而且，如果信息到达的顺序很重要，如果系统根据信息到达的顺序采取不同的行动，那么你就有可能产生不可预测的行为。 And, if it matters which order the messages arrive in, if the system takes different actions, depending on the order the messages arrive, you then have the potential for unpredictable behaviour
> 同样地，这样的系统也有可能出现死锁。我们有可能安排系统，使消息在一个循环中流动，如果时间不对，角色最终会在一个相互依赖的循环中等待对方的消息。. Similarly, it's possible for such a system to deadlock. It’s possible to arrange the system such that the messages flow in a cycle, and if the timing doesn't work out, the actors end up waiting for messages from each other in a mutually dependent loop.
> 同样，如果这有可能成为一个问题，你需要以不同的方式构建通信，这样就不会有消息的循环，也就不会有事情意外地最终相互依赖。从本质上讲，在消息传递系统中，建立一个网络协议。我们用来分析网络协议的工具，用来检测网络协议中的死锁和竞赛条件，也可以应用于基于角色的系统中的通信模式。 Again, if this is likely to be a problem, you need to structure the communication differently, so there are no loops of messages, and so there's no chance of things accidentally ending-up mutually dependent. Essentially, in message passing systems, you're building a network protocol. And the tools which we have to analyse network protocols, to detect deadlocks and detect race conditions in network protocols, can also be applied to the patterns of communication in actor based systems.

# 数据竞赛：data races

在共享内存系统中，由于不同线程之间的通信时间不同，也有可能出现这些类型的竞赛条件。而且，由于以错误的顺序获取锁，也有可能出现死锁.但还有第三种类型的竞赛，也就是所谓的数据竞赛 In shared memory systems it's also possible to get these types of race conditions, due to the timing at which communications happens between different threads. And it's also possible to get deadlocks because of acquiring locks in the wrong order. But there's also a third type of race, which is what's known as a data race.

- 在共享内存系统中，数据在概念上是从发送者移到接收者的。•	In shared memory systems, data is conceptually moved from sender to receiver
- 在实践中，由于性能的原因，数据的**引用**经常被复制，而基础数据仍然在原地。•	In practice, a reference to the data is often copied, for performance reasons, and the underlying data remains in place
- 如果数据在发送后被修改，并且修改对接收者来说通过引用是可见的，那么就会发生**数据竞赛**情况。•	A data race condition occurs if the data is modified after it is sent, and the modification is visible to the receiver via the reference
  - 无法预测接收方看到的是旧版本还是新版本，这取决于修改的时间、调度等。•	Unpredictable if the receiver sees the old or new version, depending on timing of changes, scheduling, etc.
  - 避免数据竞赛的两种方法：**不可改变的数据或所有权跟踪**•	Two approaches to avoid data races: immutable data or ownership tracking

>  现在，在共享内存系统中，当两个线程通信时，我们在概念上是将数据从一个线程转移到另一个线程。因此，从概念上讲，数据从一个线程转移到了另一个线程。发送者在发送数据后失去了对数据的访问权，而接收者则获得了访问权，因此不存在竞赛的可能性。但在实践中，为了获得良好的性能，经常发生的情况是，数据的引用被移动。由于性能的原因，底层数据仍然在原地，而且很多时候是有可能的，结果是不正确的，但是发送方有可能在数据被传递给接收方后保留对数据的引用。这就允许出现所谓的数据竞赛的可能性。 Now, in shared memory systems, when two threads communicate, we're conceptually moving the data from one thread to another. So, conceptually, the data goes from one thread, and is moved to the other thread. The sender loses access to the data after it has been sent, and the receiver gains access, and there's no potential for a race. In practice, though, in order to get good performance, what often happens is that a reference to the data is moved. And for performance reasons, the underlying data remains in place, and quite often it's possible, the result is incorrect, but it's possible for the sender to keep a reference to the data after it has been passed to the receiver. And this allows the possibility of what's known as a data race.
> 发送方和接收方都可以访问同一条数据，而发送方在发送后对其进行修改。这方面的问题是，在什么时候发生修改是不可预测的，以及它是在接收方使用该值之前还是之后变得可见。根据变化的时间，根据调度，接收方有可能看到修改后的值，也有可能看不到，从而导致不可预测的行为。 Where both the sender and the receiver have access to the same piece of data ,and the sender modifies it after it's been sent. And the problem with this, is that it's unpredictable at what point that modification happens, and whether it becomes visible to the receiver before, or after, it uses the value. Depending on the timing of the changes, depending on the scheduling, it's possible that the receiver may see the modified value, or it’s possible that it won’t, leading to unpredictable behaviour.
> 如你所料，有两种方法可以避免这种情况。一个是不可变的数据：确保数据不能改变。另一个是跟踪所有权，以确保它真的是，确保引用真的被移到了接收者那里。 And are two approaches to avoid this, as you might expect. One is immutable data: make sure the data can’t change. And the other is tracking ownership, to make sure that it really is, make sure that the reference really is moved to the receiver.

# 避免数据竞赛-不可变数据：Avoiding Data Races-Immutable Data

- **如果数据没有被修改，就不会出现竞赛条件**•	Race conditions cannot occur if data is not modified
  - **确保任何要在线程之间发送的对象都是不可变的**•	Ensure any objects to be sent between threads is immutable
  - Erlang在语言中确保了这一点→所有变量都是不可变的•	Erlang ensures this in the language → all variables are immutable
  - Scala+Akka需要程序员的约束→如果消息数据在消息发送后被修改，则可能出现竞赛条件•	Scala+Akka requires programmer discipline → potential race conditions if message data modified after message sent

> 所以，**避免数据竞赛的常用方法就是让数据变得不可改变。确保线程之间发送的任何东西都不能被修改**。So, the common approach to avoiding data races is just to make the data immutable. Make sure that anything which is sent between threads cannot be modified.
> 像Erlang这样广泛使用消息传递的语言，通过使所有变量不可变来确保这一点。在Erlang中，你根本无法改变数值，你无法改变变量的数值。这很有效，当然也避免了竞赛条件，但它迫使人们采用相当不同的编程风格。 And languages like Erlang, which make extensive use of message passing, ensure this by making all variables immutable. You simply can't change the value, you can’t change the value of a variable in Erlang. And that works, and it certainly avoids the race conditions, but it forces quite a different programming style.
> 另外，你还有像Scala这样的语言和Akka库，它们也被广泛用于消息传递系统。但该语言并不强制执行不可变性。它有工具来实现它，但它需要程序员的约束。它要求程序员跟踪哪些值可以在线程之间传递，并确保它对它们的处理是不可改变的。如果消息数据在发送后被修改，这就有可能产生竞赛条件。在这些类型的语言中，这也是一个错误的来源。 Alternatively, you have languages like Scala with the Akka library which, again, are widely used for message passing systems. But the language doesn't enforce immutability. It has tools to enable it, but it requires programmer discipline. It requires the programmer to track what values which can be passed between threads, and ensure it treats them immutably. And this opens up the potential for race conditions if message data is modified after the messages are sent. And it's a source of bugs in those types of language.

# 避免数据竞赛-所有权转移：Avoiding Data Races-Ownership Transfer

如果数据不被共享，就不会发生竞赛条件•	Race conditions cannot occur if data is not shared

- **确保对象的所有权被转移，因此发送者在发送对象后无法访问该对象**•	Ensure ownership of an object is transferred, so the sender cannot access the object after it has been sent
- 自然适合Rust。•	Natural fit for Rust:
  - 标准库提供了一个**通道**抽象•	Standard library provides a channel abstraction
  - send()函数获取要发送的数据的所有权•	The send() function takes ownership of the data to be sent
  - recv()函数返回所接收数据的所有权•	The recv() function returns ownership of the received data
  - 类型系统中通常的所有权规则确保数据一旦被发送就无法访问•	The usual ownership rules in the type system ensure the data is not accessible once it has been sent
- **如果发送者在发送后不能访问对象，就不能改变它→防止出现竞赛条件**•	If sender can’t access object once it’s been sent, can’t change it → race condition prevented

> 避免数据竞赛、避免竞赛条件的另一种方法是转移所有权。显然，如果数据不被共享，就不会发生竞赛条件。如果我们确保对象的所有权真正被转移，那么发送者在发送后就不能访问它。如果程序、编译器和运行时能够以某种方式强制执行这一点，那么你就能保证不会发生竞赛，即使这些值是可变的。The other way of avoiding data races, avoiding race conditions, is by transferring ownership. Race conditions, obviously, can't occur if the data isn't shared. If we make sure that the ownership of the object is actually being transferred, so the sender can't access it after it has been sent. And if the program, and the compiler, and the runtime, can somehow enforce that, then you're guaranteed that races can't occur, even if the values are mutable.
> 这与Rust的工作方式是自然吻合的。Rust的标准库提供了一个被称为通道的抽象，它允许线程之间进行通信，并提供了send()和recv()函数。通道上的send()函数获取要发送的数据的所有权，而由接收线程调用的recv()函数则返回该数据的所有权。 And this is a natural fit for the way Rust works. The standard library in Rust provides an abstraction known as a channel, which allows for communication between threads, and it provides send() and recv() functions. The send() function on a channel takes ownership of the data to be sent, and the recv() function, called by the receiving thread, returns ownership of that data.
> 而Rust的类型系统，因为它跟踪所有权，实际上可以使这个工作，所以一旦值被送入一个通道，因为该函数取得了所有权，发送者就不再有机会访问它。同样，在接收方，一旦接收方调用了recv()函数并返回了所有权，数据就不能再被通道访问。 And the type system of Rust, because it tracks ownership, can actually make this work, so that once the value is sent into a channel, because that function takes ownership, the sender doesn't have access to it anymore. Similarly, on the receiving side, once the receiver has called the recv() call and returned ownership, the data is not accessible by the channel anymore.
> 而Rust中通常的所有权规则确保了数据一旦被发送就不能被访问。而且你不必担心变异性，因为它保证一旦被发送，原来的线程，即发送线程，就失去了所有权。一旦对象被发送，它就不能访问它，不能改变它，所以竞赛条件就不会发生。 And the usual ownership rules in Rust ensure that the data is not accessible once it's been sent. And you don't have to worry about mutability, because it's guaranteed that once it's been sent, the original thread, the sending thread, loses ownership. It can't access the object once it's been sent, it can't change it, and so race conditions can’t happen.
> 这在Rust中运作良好，因为它有能力跟踪所有权。这在其他语言中不太行得通，因为Rust在拥有所有权跟踪方面是不寻常的。 And that works well in Rust, because it has the ability to track ownership. It doesn't work so well in other languages, because Rust is unusual in having ownership tracking.

# 消息传递效率：Aside- Efficiency of Message Passing

![](/static/2022-05-08-13-09-01.png)

- **假设不可变的消息或线性类型，消息传递有高效的实现方式**•	Assuming immutable message or linear types, message passing has efficient implementation
  - 在分布式系统中复制消息数据•	Copy message data in distributed systems
  - 在共享内存系统中传递指向数据的指针•	Pass pointer to data in shared memory systems
  - 这两种情况都不需要考虑对消息数据的共享访问•	Neither case needs to consider shared access to message data

- **垃圾收集系统经常从共享交换堆中分配消息**•	Garbage collected systems often allocate messages from a shared exchange heap
  - 与每个进程堆分开收集•	Collected separately from per-process heaps
  - 收集起来很昂贵，因为交换堆中的数据被多个线程拥有--需要同步化•	Expensive to collect, since data in exchange heap owned by multiple threads – need synchronisation
  - 每进程堆可以独立和并发地收集 - 确保良好的性能•	Per-process heaps can be collected independently and concurrently – ensures good performance

> 你需要确保系统的结构是为了避免竞赛条件，避免数据竞赛。你可以通过使消息不可改变，或者通过跟踪所有权来做到这一点。如果你做到了这两点中的任何一点，你实际上可以很有效地实现消息传递。You need to make sure that the system is structured to avoid race conditions, avoid data races. And you can either do that by making the messages immutable, or by tracking ownership. If you do either of these, you can actually implement message passing pretty efficiently.
> 在系统真的是分布式的情况下，它变成了一个在网络上被复制的消息，但在共享内存系统的情况下，它是通过传递一个指向要传输的数据的指针实现的。而且，要么数据是不可改变的，所以你不需要担心对它的锁定访问，要么类型系统已经跟踪了所有权，并保证所有权已经被转移，而且你也不需要担心在这一点上对数据的锁定访问。 In the case where the system really is distributed, it turns into a message being copied across the network, but in the case of shared memory systems, it's implemented by passing a pointer to the data be transferred. And either the data is immutable, so you don't need to worry about locking access to it, or the type system has tracked ownership and guaranteed that ownership has been transferred, and again you don't need to worry about locking access to the data at that point.
> 不过，如果你有一个垃圾收集器，这些类型的系统确实是相互影响的。这里的问题是，在线程之间传递的数据，有可能被不同的线程访问。 These types of systems do, though, interact, if you have a garbage collector. The issue here is that the data, which has been passed between threads, is potentially accessible from the different threads. 
> 而且，如果系统中的多个线程都在运行一个垃圾收集器，那么你就必须协调两个线程之间的垃圾收集，因为你有这些共享值。你不想做的是，让一个线程进入另一个线程使用的堆区域来执行垃圾收集，因为这涉及到锁定另一个线程访问的所有值，并可能在系统运行时停止另一个线程。And, if the multiples threads in the system are each running a garbage collector, you then have to coordinate the garbage collection between the two threads, because you have these shared values. And what you don't want to do, is have one thread reaching into the region of the heap used by another to perform garbage collection, because this involves locking all of the values accessed by the other thread, and potentially stopping the other thread while the system is running
> 你希望每个线程都能单独收集其垃圾。通常的解决方法是，线程之间共享的值，因为它们是通过消息传递的，被放入所谓的交换堆中。系统为潜在的共享值分配了一个单独的内存区域，并确保对这些值的任何访问都是同步的。. You want each thread to be able to collect its garbage separately. The usual fix for this, is that values which are shared between threads, because they've been passed in a message, are put into what's known as an exchange heap. The system allocates a separate region of memory for potentially shared values and it ensures that any access to these values is synchronised.
> 因此，一个锁被获取，这确保了垃圾收集器可以安全地从该堆中寻找指针。它只需要在访问交换堆时锁定内存访问，期望交换堆中的值数量非常少，所以垃圾收集也很快。 So a lock is acquired, and this makes sure that the garbage collector can safely look for pointers from that heap. And it only has to lock memory access while it's accessing the exchange heap, which hopefully has a very small number of values in it, and so is quick to garbage collect.
> 绝大多数的数据在线程之间是不共享的，所以可以用通常的方式进行垃圾回收。因此，如果你有垃圾收集，并且你在多个线程之间传递数据，这可以显著提高性能。 The vast majority of the data is not shared between threads, and so can be garbage collected in the usual way. So this can improve performance significantly, if you have garbage collection, and you're passing data between multiple threads.

# Summary

- 消息传递作为一种替代的并发机制•	Message passing as an alternative concurrency mechanism
- 越来越流行•	Increasingly popular
  - Erlang, Scala+Akka (或Java+Akka...)
  - Rust
  - Go、ZeroMQ等。- 未经检查的消息传递 unchecked message passing

- 易于推理，简单的编程模型•	Easy to reason about, simple programming model
- 提供的数据是不可变的，或者所有权是可追踪的•	Provided data is immutable, or ownership is tracked

>  消息传递是一种替代性的并发机制。而且它越来越受欢迎。它在Erlang等语言中可用，在Scala的Akka工具包中也可用，而且效果非常好。它在Rust中可用，但在那里也许并不流行，人们似乎喜欢异步的方法，我们将在Rust的下一个讲座中讨论，但消息传递是肯定可以的。 message passing is an alternative concurrency mechanism. And it's getting increasingly popular. It’s available in languages like Erlang, and in Scala with the Akka toolkit, and it works extremely well. It's available in Rust, it's perhaps not so fashionable there, people seem to like the asynchronous approach which we'll talk about in the next lecture in Rust, but message passing is certainly possible. 
> 在Go这样的语言中，通过Go的例程，以及像ZeroMQ这样的C程序系统，都是可以实现的，等等。And it's possible in languages like Go, with Go routines, and with systems like ZeroMQ for C programs, and so. 
> 它之所以受欢迎，是因为它很容易推理。这是一个简单的编程模型。我们习惯于构建网络系统，而它为线程之间的通信带来了相同的编程模型。它使通信变得明确，信息的传递也很清楚。如果你有所有权跟踪，或者如果数据是不可改变的，它也是相当安全的。由于消息之间的排序，你仍然有可能出现竞赛条件，但它避免了很多多线程代码的同步问题。 the reason it's popular is because it's easy to reason about. It's a simple programming model. We used to building networked systems, and it brings in the same programming model for communication between threads. And it makes the communication explicit, and it's clear when messages are being passed. And if you have ownership tracking, or if the data is immutable, it's also pretty safe. You still have the potential for race conditions, due to the ordering between messages, but it avoids a lot of the synchronisation issues with multi-threaded code.

# ================