# Content

* [Content](#content)
* [We should model the errors](#we-should-model-the-errors)
* [附加错误：Additive errors](#附加错误additive-errors)
* [En as a random variable](#en-as-a-random-variable)
* [离散和连续型随机变量：Discrete and continuous RVs](#离散和连续型随机变量discrete-and-continuous-rvs)
  * [离散型随机变量：Discrete RVs](#离散型随机变量discrete-rvs)
  * [连续型随机变量：Continuous RVs](#连续型随机变量continuous-rvs)
* [联合概率和密度：Joint probabilities and densities](#联合概率和密度joint-probabilities-and-densities)
* [耦合/独立：Dependence/Independence](#耦合独立dependenceindependence)
* [条件概率：Conditioning](#条件概率conditioning)
  * [连续RV-条件](#连续rv-条件)
* [高斯模型:Gaussian model](#高斯模型gaussian-model)
* [Generating data](#generating-data)
* [随机变量t：t is a random variable too](#随机变量tt-is-a-random-variable-too)
* [似然性：Likelihood](#似然性likelihood)
* [Summary](#summary)
* [补充：如何生成随机变量的高斯概率密度模型](#补充如何生成随机变量的高斯概率密度模型)
* [===============](#)
* [似然性例子：Likelihood Example](#似然性例子likelihood-example)
* [似然性优化：Likelihood Optimisation](#似然性优化likelihood-optimisation)
* [最佳参数：Optimum parameters](#最佳参数optimum-parameters)
* [参数估计可信度：Confidence in parameter estimates](#参数估计可信度confidence-in-parameter-estimates)
* [期望值：Expectations](#期望值expectations)
  * [离散型RV期望值](#离散型rv期望值)
  * [连续型RV期望值](#连续型rv期望值)
  * [general](#general)
  * [Gaussians Distribution例子](#gaussians-distribution例子)
* [E{w} & cov{w}](#ew--covw)
* [cov{w}](#covw)
  * [例子](#例子)
* [Summary](#summary-1)
* [预测：Predictions](#预测predictions)
  * [Prediction & Variance](#prediction--variance)
* [预测例子](#预测例子)
  * [Not complex enough model – more ‘noise’](#not-complex-enough-model--more-noise)
  * [Too complex model – parameters not well defined](#too-complex-model--parameters-not-well-defined)
* [Olympic prediction](#olympic-prediction)
* [可以基于似然性选择模型吗：Can we use likelihood to choose models?](#可以基于似然性选择模型吗can-we-use-likelihood-to-choose-models)
* [Summary](#summary-2)

# We should model the errors

We know they’re there - shouldn’t ignore them.

![](/static/2021-10-21-04-31-48.png)
![](/static/2021-10-21-04-38-21.png)

# 附加错误：Additive errors

![](/static/2021-10-21-04-48-54.png)

* 需要**引入随机变量**来model errors
  * n不同，误差不同
  * 可正可负
  * 与n之间没有直接关联

# En as a random variable

episilon

![](/static/2021-10-21-04-54-28.png)

* 不知道X会取哪个值，但是知道X能取的值

# 离散和连续型随机变量：Discrete and continuous RVs

![](/static/2021-10-21-04-58-36.png)

## 离散型随机变量：Discrete RVs

![](/static/2021-10-21-05-11-10.png)
Discrete RVs defines by probabilities of di↵erent events taking place. E.g. probability of random variable X taking value x: **离散 RV 由不同事件发生的概率定义。例如。随机变量 X 取值 x 的概率**：

## 连续型随机变量：Continuous RVs

![](/static/2021-10-21-05-28-33.png)

* 通过density function密度函数可以计算概率
  * 不是概率，是区间内可能有多少个值？
  * 面积/积分，才是概率

# 联合概率和密度：Joint probabilities and densities

![](/static/2021-10-21-05-35-50.png)

* 联合密度

# 耦合/独立：Dependence/Independence

![](/static/2021-10-21-22-15-02.png)
![](/static/2021-10-21-22-17-08.png)

* 独立/非独立会影响联合概率

# 条件概率：Conditioning

当两个RV相互依赖

![](/static/2021-10-21-22-33-29.png)

* 因为相互依赖，可以利用条件概率

## 连续RV-条件

![](/static/2021-10-21-22-38-51.png)

# 高斯模型:Gaussian model

连续型随机变量常用模型

![](/static/2021-10-21-22-48-11.png)

![](/static/2021-10-21-22-58-06.png)

# Generating data

高斯模型怎么关联error terms的？（怎么关联原模型

![](/static/2021-10-21-22-58-54.png)

![](/static/2021-10-21-23-08-28.png)

* 通过probability distribution for the random var episilon

---

![](/static/2021-10-21-23-22-17.png)

* 根据数据集，先计算模型预测值

![](/static/2021-10-21-23-23-09.png)

* 选取mean，std计算误差，附加在原模型（预测值）上

![](/static/2021-10-21-23-25-15.png)

* 调整std

![](/static/2021-10-21-23-32-47.png)
![](/static/2021-10-22-05-23-08.png)

![](/static/2021-10-22-07-23-30.png)

# 随机变量t：t is a random variable too

![](/static/2021-10-22-08-15-18.png)

* t预测值本身也是个RV，可以有密度函数
  * 但是tn固定？（数据集）

![](/static/2021-10-22-08-26-52.png)
![](/static/2021-10-27-02-32-49.png)

* 冲突：给定数据集，tn已知（固定），但是t又存在概率密度？ --- 其实这种情况下，求得是**似然性**
  * 似然性 - 未知参数的函数
* 似然性越高，模型越好？
* 密度函数
  * 告诉给定一个xn，，生成特定tn的似然性？

# 似然性：Likelihood

![](/static/2021-10-22-08-55-03.png)
![](/static/2021-10-22-08-36-27.png)

model 1
![](/static/2021-10-22-08-45-57.png)
![](/static/2021-10-22-08-46-15.png)

model 2
![](/static/2021-10-22-08-46-59.png)
![](/static/2021-10-22-08-47-15.png)

model 3
![](/static/2021-10-22-08-48-16.png)

* higher likelihood is the better fit model would be
* 似然性越高，模型越好

# Summary

![](/static/2021-10-22-08-57-18.png)

# 补充：如何生成随机变量的高斯概率密度模型

![](/static/2021-10-22-09-20-37.png)
![](/static/2021-10-22-09-29-18.png)
![](/static/2021-10-22-09-29-27.png)

# ===============

# 似然性例子：Likelihood Example

![](/static/2021-10-27-02-37-44.png)

![](/static/2021-10-27-02-38-10.png)
![](/static/2021-10-27-02-38-18.png)

![](/static/2021-10-27-02-38-41.png)

* model3似然性最高
* 合并两个点（多个点）
  * 因为t1,t2都是连续型RV，可以表示其联合密度，相当于t1,t2密度的product
  * 泛化这个步骤->合并所有t（tn）

# 似然性优化：Likelihood Optimisation

![](/static/2021-10-27-03-40-13.png)

* tn之间是条件（conditionally）独立的，，假设来自同一模型（w, σ相同）

![](/static/2021-10-27-03-41-43.png)

* 找到最大化似然性的配置

![](/static/2021-10-27-03-47-27.png)
![](/static/2021-10-27-03-48-11.png)

* 为什么改写成对Log似然性的优化

# 最佳参数：Optimum parameters

![](/static/2021-10-27-03-49-59.png)
![](/static/2021-10-27-03-50-16.png)

![](/static/2021-10-27-03-54-54.png)

* 这个配置预测有多少可信度？

# 参数估计可信度：Confidence in parameter estimates

![](/static/2021-10-27-03-59-30.png)

* 希望数据越多越往true para收敛

![](/static/2021-10-27-04-03-07.png)

* 使用的数据集部分不同，参数预测不同，可信度也不同
  * 比如数据1->0,, 0->10，可信度肯定不同
* **以上步骤，需要学习好几次。。需要引入期望值来简化（直接计算estimate可信度?**

# 期望值：Expectations

计算可信度

![](/static/2021-10-27-04-51-33.png)

* 这么计算，样本量不够，，
  * 但是可以直接计算**期望值**

## 离散型RV期望值

![](/static/2021-10-27-05-00-16.png)

## 连续型RV期望值

![](/static/2021-10-27-05-01-26.png)

## general

x - scalar

![](/static/2021-10-27-05-10-56.png)

x - RV

![](/static/2021-10-27-05-40-44.png)

## Gaussians Distribution例子

![](/static/2021-10-27-05-42-50.png)

# E{w} & cov{w}

![](/static/2021-10-27-05-47-57.png)

![](/static/2021-10-27-07-02-35.png)
![](/static/2021-10-27-07-11-15.png)

* w - (condition - true para)
* w(bar) - estimate

# cov{w}

![](/static/2021-10-27-07-19-26.png)

* a,c - w0,w1还能改多少的情况下仍能拟合
* b
  * 如 <0, a!=c, w0, w1 negatively correlated. increase w0 may cause loss in w1

![](/static/2021-10-27-07-28-27.png)

## 例子

![](/static/2021-10-27-07-36-59.png)

# Summary

![](/static/2021-10-27-07-37-11.png)

# 预测：Predictions

![](/static/2021-10-27-08-43-35.png)
![](/static/2021-10-27-09-05-32.png)

![](/static/2021-10-27-09-08-38.png)

## Prediction & Variance

![](/static/2021-10-27-09-12-18.png)

# 预测例子

![](/static/2021-10-27-09-16-54.png)

![](/static/2021-10-27-09-17-08.png)

![](/static/2021-10-27-09-26-25.png)

## Not complex enough model – more ‘noise’

![](/static/2021-10-27-09-28-18.png)

## Too complex model – parameters not well defined

![](/static/2021-10-27-09-30-50.png)

# Olympic prediction

![](/static/2021-10-27-09-32-48.png)

![](/static/2021-10-27-09-35-21.png)

# 可以基于似然性选择模型吗：Can we use likelihood to choose models?

![](/static/2021-10-27-09-37-35.png)

* 不能
  * 类似高阶模型的loss越来越小，但不是最好的
  * 越复杂模型，似然性越高，estimate noise level越小

# Summary

![](/static/2021-10-27-09-41-53.png)